# core/pipeline_v5.py - æ™ºèƒ½è§†é¢‘å‰ªè¾‘æµæ°´çº¿ v5.6 (åˆ†å±‚ç”Ÿæˆ+ä¸Šä¸‹æ–‡æ„ŸçŸ¥ç‰ˆ)
"""
SmartVideoClipper v5.6 - å…¨çƒç¬¬ä¸€çš„æ™ºèƒ½è§†é¢‘è§£è¯´

v5.6 æ ¸å¿ƒæ”¹è¿›ï¼š
1. [NEW] åˆ†å±‚ç”Ÿæˆ - å…ˆç”Ÿæˆæ•…äº‹æ¡†æ¶ï¼Œå†æŒ‰æ¡†æ¶ç”Ÿæˆè§£è¯´
2. [NEW] ä¸Šä¸‹æ–‡çª—å£ - æ¯ä¸ªåœºæ™¯è€ƒè™‘å‰2å2åœºæ™¯
3. [NEW] åŠ¨æ€æ¯”ä¾‹ - æ ¹æ®åœºæ™¯ç‰¹å¾è‡ªåŠ¨è®¡ç®—è§£è¯´æ¯”ä¾‹(30%-75%)
4. [NEW] é™éŸ³å¤„ç† - æ£€æµ‹å¹¶AIæ‰©å±•å¡«å……é™éŸ³æ®µè½
5. [NEW] é’©å­å¼€åœº - è‡ªåŠ¨ç”Ÿæˆå¸å¼•äººçš„å¼€åœºç™½
6. [NEW] æ‚¬å¿µç»“å°¾ - è‡ªåŠ¨ç”Ÿæˆå¼•å‘æœŸå¾…çš„ç»“å°¾
7. [NEW] åŠ¨æ€è¯­é€Ÿ - TTSæ”¯æŒ0.85x-1.15xè¯­é€Ÿè°ƒæ•´

v5.4 åŸºç¡€ä¿ç•™ï¼š
- æ‰¹é‡è§£è¯´ç”Ÿæˆï¼ˆ10åœºæ™¯/æ‰¹ï¼‰
- å¹¿å‘Šæ£€æµ‹å’Œè¿‡æ»¤
- ç»Ÿä¸€ç¼–ç å‚æ•°
- è¯­éŸ³è¯†åˆ«ä¼˜åŒ–

å¤„ç†æµç¨‹ï¼š
Step 0: é¢„å¤„ç†ï¼ˆå»ç‰‡å¤´ç‰‡å°¾ + å¹¿å‘Šæ£€æµ‹ï¼‰
Step 1: è¯­éŸ³è¯†åˆ«ï¼ˆè·å–å¯¹è¯ï¼‰
Step 2: åœºæ™¯åˆ†æï¼ˆæ ‡è®°ç²¾å½©/è¿‡æ¸¡ï¼‰
Step 3: æ™ºèƒ½è§£è¯´ï¼ˆåˆ†å±‚ç”Ÿæˆ + ä¸Šä¸‹æ–‡æ„ŸçŸ¥ï¼‰
Step 4: æ—¶é•¿æ§åˆ¶ï¼ˆåŠ¨æ€æ¯”ä¾‹ + é™éŸ³å¤„ç†ï¼‰
Step 5: TTSåˆ†æ®µåˆæˆï¼ˆåŠ¨æ€è¯­é€Ÿï¼‰
Step 6: ç‰‡æ®µå¤„ç†ï¼ˆåŸå£°/è§£è¯´åˆ†å¼€ï¼‰
Step 7: è¾“å‡ºæˆå“
"""

import os
import sys
import asyncio
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Tuple

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "core"))

# ç¯å¢ƒé…ç½®
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"

# GPUåŠ é€Ÿæ£€æµ‹
try:
    from gpu_encoder import get_encoder, is_hardware_available
    GPU_ENCODER = get_encoder()
except ImportError:
    GPU_ENCODER = None
    def is_hardware_available():
        return False


PROCESS_STEPS_V5 = {
    0: "é¢„å¤„ç†",
    1: "è¯­éŸ³è¯†åˆ«", 
    2: "åœºæ™¯åˆ†æ",
    3: "æ™ºèƒ½è§£è¯´",
    4: "æ—¶é•¿æ§åˆ¶",
    5: "TTSåˆ†æ®µåˆæˆ",
    6: "ç‰‡æ®µå¤„ç†",
    7: "è¾“å‡ºæˆå“",
}


class VideoPipelineV5:
    """
    SmartVideoClipper v5.0 å¤„ç†æµæ°´çº¿ (å·²ä¿®å¤ç‰ˆ)
    
    æ ¸å¿ƒæ”¹è¿›ï¼š
    - æ¯ä¸ªç‰‡æ®µç‹¬ç«‹å¤„ç†éŸ³é¢‘ï¼ˆä¸æ˜¯å…¨ç¨‹æ··éŸ³ï¼‰
    - æ¯ä¸ªè§£è¯´åœºæ™¯å•ç‹¬ç”ŸæˆTTS
    - è§£è¯´æ—¶é•¿è‡ªåŠ¨é€‚é…åœºæ™¯æ—¶é•¿
    - æ™ºèƒ½é€‰æ‹©åœºæ™¯ä»¥è¾¾åˆ°ç›®æ ‡æ—¶é•¿
    """
    
    def __init__(self):
        self.start_time = None
        self.work_dir = None
        
    async def process(
        self,
        video_path: str,
        output_name: str,
        title: str = "",
        style: str = "å¹½é»˜",
        min_duration: int = 180,   # æœ€çŸ­3åˆ†é’Ÿ
        max_duration: int = 900,   # æœ€é•¿15åˆ†é’Ÿ
        media_type: str = "auto",  # auto/tv/movie
        episode: int = 0,          # ç¬¬å‡ é›†/éƒ¨ï¼ˆ0=è‡ªåŠ¨æ£€æµ‹ï¼‰
        progress_callback=None
    ) -> Dict:
        """
        å¤„ç†è§†é¢‘
        
        å‚æ•°ï¼š
            video_path: è§†é¢‘è·¯å¾„
            output_name: è¾“å‡ºåç§°
            title: ä½œå“åç§°
            style: è§£è¯´é£æ ¼
            min_duration: æœ€çŸ­æ—¶é•¿ï¼ˆç§’ï¼‰
            max_duration: æœ€é•¿æ—¶é•¿ï¼ˆç§’ï¼‰
            media_type: åª’ä½“ç±»å‹ (autoè‡ªåŠ¨/tvç”µè§†å‰§/movieç”µå½±)
            episode: é›†æ•°/éƒ¨æ•° (0è¡¨ç¤ºè‡ªåŠ¨ä»æ–‡ä»¶åè§£æ)
            progress_callback: è¿›åº¦å›è°ƒ
        """
        self.start_time = datetime.now()
        
        # åˆ›å»ºå·¥ä½œç›®å½•
        self.work_dir = project_root / f"workspace_{output_name}"
        self.work_dir.mkdir(exist_ok=True)
        
        def report_progress(step: int, message: str, sub_step: str = ""):
            """æŠ¥å‘Šè¿›åº¦ - å®æ—¶è¾“å‡º"""
            import sys
            elapsed = (datetime.now() - self.start_time).seconds
            pct = int(step / 8 * 100)
            
            # è¿›åº¦æ¡
            bar_filled = pct // 3
            bar_empty = 33 - bar_filled
            bar = '#' * bar_filled + '-' * bar_empty
            
            print(f"\n{'='*60}", flush=True)
            print(f"[{datetime.now().strftime('%H:%M:%S')}] [{bar}] {pct}%", flush=True)
            print(f"[{datetime.now().strftime('%H:%M:%S')}] æ­¥éª¤ {step}/8: {PROCESS_STEPS_V5.get(step, 'æœªçŸ¥')}", flush=True)
            print(f"[{datetime.now().strftime('%H:%M:%S')}] {message}", flush=True)
            if sub_step:
                print(f"[{datetime.now().strftime('%H:%M:%S')}]    -> {sub_step}", flush=True)
            print(f"[{datetime.now().strftime('%H:%M:%S')}] å·²è€—æ—¶: {elapsed}ç§’ ({elapsed//60}åˆ†{elapsed%60}ç§’)", flush=True)
            print(f"{'='*60}", flush=True)
            sys.stdout.flush()
            
            if progress_callback:
                progress_callback(step, message, pct)
        
        def log(msg: str):
            """å®æ—¶æ—¥å¿—è¾“å‡º"""
            import sys
            print(f"[{datetime.now().strftime('%H:%M:%S')}] {msg}", flush=True)
            sys.stdout.flush()
        
        # è‡ªåŠ¨æ£€æµ‹åª’ä½“ç±»å‹å’Œé›†æ•°
        from plot_fetcher import parse_episode_from_filename, extract_title_from_filename
        
        if not title:
            title = extract_title_from_filename(video_path)
        
        # è‡ªåŠ¨è§£æé›†æ•°
        auto_season, auto_episode = parse_episode_from_filename(video_path)
        if episode == 0:
            episode = auto_episode
        
        # è‡ªåŠ¨åˆ¤æ–­åª’ä½“ç±»å‹ï¼ˆæœ‰é›†æ•°æ ‡è®° â†’ ç”µè§†å‰§ï¼‰
        if media_type == "auto":
            if auto_episode > 1 or "E0" in video_path.upper() or "ç¬¬" in video_path and "é›†" in video_path:
                media_type = "tv"
            else:
                media_type = "movie"  # é»˜è®¤ç”µå½±
        
        # æ‰“å°å¯åŠ¨ä¿¡æ¯
        print("\n" + "="*60)
        print("[PIPELINE] SmartVideoClipper v5.8.0 - å…¨çƒæœ€ä¼˜Structuredè§£è¯´")
        print("="*60)
        print("   v5.7 æ ¸å¿ƒä¼˜åŒ–:")
        print("   1. [OK] åƒåœ¾æ–‡å­—æ¸…æ´—ï¼ˆè¿‡æ»¤AIæ€è€ƒæ®‹ç•™ï¼‰")
        print("   2. [OK] 100%AIç”Ÿæˆï¼ˆå¤šçº§é‡è¯•+å…œåº•ï¼‰")
        print("   3. [OK] é£æ ¼è‡ªåŠ¨é€‚é…ï¼ˆæŒ‰è§†é¢‘ç±»å‹ï¼‰")
        print("   4. [OK] åºŸé™¤å›ºå®šæ¯”ä¾‹ï¼ˆæ™ºèƒ½åˆ¤æ–­ï¼‰")
        print("   5. [OK] é™éŸ³æ™ºèƒ½å¡«å……ï¼ˆåœºæ™¯æ„ŸçŸ¥ï¼‰")
        print("   6. [OK] ä¸ªæ€§åŒ–é’©å­ï¼ˆå‰§æƒ…å…³è”ï¼‰")
        print("   7. [OK] GPUç¡¬ä»¶åŠ é€Ÿç¼–ç ")
        print("="*60)
        
        # GPUåŠ é€ŸçŠ¶æ€
        if GPU_ENCODER:
            gpu_info = GPU_ENCODER.get_info()
            if gpu_info['is_hardware']:
                print(f"   [GPU] åŠ é€Ÿ: {gpu_info['name']} (10xé€Ÿæå‡!)")
            else:
                print(f"   [GPU] ä¸å¯ç”¨ï¼Œä½¿ç”¨CPUç¼–ç ")
        else:
            print(f"   [GPU] æ£€æµ‹æ¨¡å—æœªåŠ è½½")
        
        print("="*60)
        print(f"   å¼€å§‹æ—¶é—´: {self.start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"   è¾“å…¥è§†é¢‘: {video_path}")
        print(f"   ä½œå“åç§°: {title}")
        media_type_cn = "ç”µè§†å‰§" if media_type == "tv" else "ç”µå½±"
        print(f"   åª’ä½“ç±»å‹: {media_type_cn}")
        if media_type == "tv":
            print(f"   å½“å‰é›†æ•°: ç¬¬{episode}é›†")
            print(f"   è§£è¯´ç­–ç•¥: è®²è¿°æœ¬é›†æ•…äº‹ï¼ˆ60%è§£è¯´+40%åŸå£°ï¼‰")
        else:
            print(f"   å½“å‰éƒ¨æ•°: ç¬¬{episode}éƒ¨")
            print(f"   è§£è¯´ç­–ç•¥: ç²¾å½©ç‰‡æ®µé›†é”¦ï¼ˆ40%è§£è¯´+60%åŸå£°ï¼‰")
        print(f"   è§£è¯´é£æ ¼: {style}")
        print(f"   æ—¶é•¿èŒƒå›´: {min_duration//60}-{max_duration//60}åˆ†é’Ÿ")
        print("="*60 + "\n")
        
        try:
            # ========== Step 0: é¢„å¤„ç† ==========
            report_progress(0, "æ£€æµ‹å¹¶å»é™¤ç‰‡å¤´ç‰‡å°¾ã€å¹¿å‘Š...")
            
            from intro_outro_detect import auto_trim_intro_outro
            # è¿”å›å€¼: (è¾“å‡ºè·¯å¾„, ç‰‡å¤´ç»“æŸæ—¶é—´, ç‰‡å°¾å¼€å§‹æ—¶é—´)
            trim_result = auto_trim_intro_outro(video_path, str(self.work_dir))
            
            if isinstance(trim_result, tuple):
                processed_video = trim_result[0]
            else:
                processed_video = trim_result
            
            if not processed_video or not os.path.exists(processed_video):
                processed_video = video_path
                print("   [INFO] æ— éœ€è£å‰ªï¼Œä½¿ç”¨åŸè§†é¢‘")
            
            # å¹¿å‘Šæ£€æµ‹ï¼ˆç¨ååœ¨æ—¶é—´çº¿è¿‡æ»¤ä¸­ä½¿ç”¨ï¼‰
            detected_ads = []
            try:
                from ad_detector import AdDetector
                ad_detector = AdDetector()
                detected_ads = ad_detector.detect_ads(processed_video)
            except Exception as e:
                print(f"   [WARN] å¹¿å‘Šæ£€æµ‹è·³è¿‡: {e}")
            
            # ========== Step 1: è¯­éŸ³è¯†åˆ« ==========
            report_progress(1, "è¯†åˆ«è§†é¢‘ä¸­çš„å¯¹è¯...", "è¿™æ˜¯æœ€è€—æ—¶çš„æ­¥éª¤ï¼Œé¢„è®¡10-15åˆ†é’Ÿ")
            log("   [Step1] å¼€å§‹è¯­éŸ³è¯†åˆ«...")
            
            from transcribe import transcribe_video
            srt_path = str(self.work_dir / "subtitles.srt")
            # ä¼ é€’media_typeå’Œtitleï¼Œä¼˜åŒ–ä¸­æ–‡è¯†åˆ«è´¨é‡
            segments, full_text = transcribe_video(
                processed_video, 
                output_srt=srt_path,
                media_type=media_type,
                title=title
            )
            
            log(f"   [Step1] è¯­éŸ³è¯†åˆ«å®Œæˆ! å…± {len(segments)} æ®µå¯¹è¯")
            
            # ========== Step 2: åœºæ™¯åˆ†æ ==========
            report_progress(2, "åˆ†æè§†é¢‘åœºæ™¯...", "åŒ…å«å‰§æƒ…è·å–å’Œåœºæ™¯æ£€æµ‹")
            log("   [Step2] å¼€å§‹åœºæ™¯åˆ†æ...")
            
            from scene_detect import detect_scenes
            from smart_importance import calculate_scene_importance
            from plot_fetcher import PlotFetcher
            
            # è·å–å‰§æƒ…ä¿¡æ¯ï¼ˆç”µè§†å‰§ï¼šè·å–åˆ†é›†å‰§æƒ…ï¼‰
            log("   [Step2] 2.1 è·å–å‰§æƒ…ä¿¡æ¯...")
            plot_fetcher = PlotFetcher()
            plot_info = plot_fetcher.fetch(
                title=title,
                media_type=media_type,
                season=auto_season,
                episode=episode
            )
            plot_fetcher.close()
            log("   [Step2]     å‰§æƒ…è·å–å®Œæˆ")
            
            # æå–åˆ†é›†å‰§æƒ…ï¼ˆç”¨äºè§£è¯´å¼•æ“ï¼‰
            episode_plot = ""
            if media_type == "tv":
                episode_plot = plot_info.get('episode_overview', '') or plot_info.get('overview', '')
                if episode_plot:
                    log(f"   [Step2]     ç¬¬{episode}é›†å‰§æƒ…: {episode_plot[:60]}...")
                else:
                    # ä½¿ç”¨AIä»å­—å¹•æ€»ç»“æœ¬é›†å‰§æƒ…
                    log("   [Step2] 2.2 ä½¿ç”¨AIæ€»ç»“æœ¬é›†å‰§æƒ…...")
                    from plot_fetcher import summarize_plot_from_transcript
                    episode_plot = summarize_plot_from_transcript(full_text, segments)
                    if episode_plot:
                        log(f"   [Step2]     AIæ€»ç»“: {episode_plot[:60]}...")
            
            # æ£€æµ‹åœºæ™¯
            log("   [Step2] 2.3 æ£€æµ‹è§†é¢‘åœºæ™¯ï¼ˆå¯èƒ½éœ€è¦1-2åˆ†é’Ÿï¼‰...")
            scenes_dir = str(self.work_dir / "scenes")
            raw_scenes, _ = detect_scenes(processed_video, scenes_dir)  # è§£åŒ…å…ƒç»„
            log(f"   [Step2]     æ£€æµ‹åˆ° {len(raw_scenes)} ä¸ªåœºæ™¯")
            
            # è®¡ç®—é‡è¦æ€§å¹¶å…³è”å¯¹è¯
            analyzed_scenes = []
            for i, scene in enumerate(raw_scenes):
                scene_start = scene['start']  # ä¿®æ­£é”®å
                scene_end = scene['end']      # ä¿®æ­£é”®å
                
                # æ‰¾åˆ°è¯¥åœºæ™¯å†…çš„å¯¹è¯
                scene_dialogue = ""
                for seg in segments:
                    if seg['start'] >= scene_start and seg['end'] <= scene_end:
                        scene_dialogue += seg['text'] + " "
                    elif seg['start'] < scene_end and seg['end'] > scene_start:
                        scene_dialogue += seg['text'] + " "
                
                scene_dialogue = scene_dialogue.strip()
                
                # æ£€æµ‹æƒ…æ„Ÿ
                emotion = self._detect_emotion(scene_dialogue)
                
                # è®¡ç®—é‡è¦æ€§
                importance = calculate_scene_importance(
                    scene_dialogue, 
                    scene_end - scene_start,
                    emotion
                )
                
                analyzed_scenes.append({
                    'scene_id': i + 1,
                    'start_time': scene_start,
                    'end_time': scene_end,
                    'dialogue': scene_dialogue,
                    'emotion': emotion,
                    'importance': importance,
                })
            
            log(f"   [Step2]     åœºæ™¯åˆ†æå®Œæˆ")
            
            # ========== Step 3: æ™ºèƒ½è§£è¯´ (v5.8 Structuredæ ¼å¼+åˆ†å±‚ç”Ÿæˆ) ==========
            from narration_engine import NarrationEngine, detect_video_genre, get_optimal_style
            
            # v5.8æ–°å¢ï¼šStructuredæ ¼å¼ç¡®ä¿100%æˆåŠŸç‡
            detected_genre = detect_video_genre(title, episode_plot or "")
            optimal_style_config = get_optimal_style(detected_genre)
            
            # v5.8ï¼šStructuredæ ¼å¼+è‡ªåŠ¨é£æ ¼æ£€æµ‹
            if style == "å¹½é»˜":  # é»˜è®¤å€¼ï¼Œå¯èƒ½æœªæŒ‡å®š
                actual_style = optimal_style_config['prompt_style']
                style_name = optimal_style_config['name']
            else:
                actual_style = style
                style_name = style
            
            log(f"   [Step3] v5.9 RTX4060ä¼˜åŒ–: æ£€æµ‹ç±»å‹={detected_genre}, é£æ ¼={style_name}")
            report_progress(3, f"ç”Ÿæˆ{style_name}é£æ ¼è§£è¯´ï¼ˆv5.9 RTX4060æ™ºèƒ½ç®¡ç†ï¼‰...", "100%æˆåŠŸç‡ + æ˜¾å­˜ä¼˜åŒ–")

            # v5.9æ–°å¢ï¼šè°ƒè¯•æ¨¡å¼æ˜¾å­˜æŠ¥å‘Š
            if os.getenv('SMART_CLIPPER_DEBUG', 'false').lower() == 'true':
                try:
                    from utils.gpu_manager import GPUManager
                    mem_info = GPUManager.get_memory_info()
                    if mem_info:
                        log(".1f"                except:
                    pass

            log("   [Step3] å¼€å§‹æ™ºèƒ½è§£è¯´ç”Ÿæˆ v5.9...")

            # v5.9æ–°å¢ï¼šåˆå§‹åŒ–å‰æ˜¾å­˜ç›‘æ§
            try:
                from utils.gpu_manager import GPUManager
                log("   [Step3] 3.0 RTX 4060æ˜¾å­˜ç›‘æ§...")
                if not GPUManager.monitor_and_cleanup(0.75):  # 75%é˜ˆå€¼ï¼Œç•™æœ‰ä½™é‡
                    log("   [Step3] âš ï¸ æ˜¾å­˜æ¸…ç†å¤±è´¥ï¼Œä½¿ç”¨å…¼å®¹æ¨¡å¼")
                else:
                    mem_info = GPUManager.get_memory_info()
                    log(".1%")
            except ImportError:
                log("   [Step3] GPUç®¡ç†å™¨ä¸å¯ç”¨ï¼Œä½¿ç”¨æ ‡å‡†æ¨¡å¼")

            # v5.9: åˆå§‹åŒ–è§£è¯´å¼•æ“ï¼ˆåˆ†çº§æ¨¡å‹ç­–ç•¥ï¼‰
            log("   [Step3] 3.1 åˆå§‹åŒ–è§£è¯´å¼•æ“ v5.9...")
            total_episodes = 1  # é»˜è®¤1é›†ï¼Œå¯ä»å¤–éƒ¨ä¼ å…¥
            engine = NarrationEngine(
                use_ai=True,
                media_type=media_type,
                episode=episode,
                total_episodes=total_episodes
            )

            log("   [Step3] 3.2 åˆ†å±‚ç”Ÿæˆè§£è¯´ (æ¡†æ¶â†’åœºæ™¯â†’ä¸Šä¸‹æ–‡)...")
            # v5.6: ä¼ å…¥main_characterå‚æ•°
            main_character = ""  # å¯ä»å‰§æƒ…ä¸­æå–
            if episode_plot:
                # ç®€å•æå–ï¼šæ‰¾åˆ°ç¬¬ä¸€ä¸ªå‡ºç°çš„äººå
                import re
                name_match = re.search(r'([é«˜æç‹å¼ åˆ˜é™ˆ][^\sï¼Œã€‚]{0,2})', episode_plot)
                if name_match:
                    main_character = name_match.group(1)

            scene_segments, narration_text = engine.analyze_and_generate(
                analyzed_scenes, 
                title, 
                actual_style,  # v5.7.1ä¿®å¤ï¼šä½¿ç”¨è‡ªåŠ¨æ£€æµ‹çš„é£æ ¼
                episode_plot=episode_plot,
                main_character=main_character
            )
            
            # v5.6: è·å–é’©å­å¼€åœºå’Œæ‚¬å¿µç»“å°¾
            hook_opening = getattr(engine, 'hook_opening', '')
            suspense_ending = getattr(engine, 'suspense_ending', '')
            if hook_opening:
                log(f"   [Step3]     é’©å­å¼€åœº: {hook_opening[:40]}...")
            if suspense_ending:
                log(f"   [Step3]     æ‚¬å¿µç»“å°¾: {suspense_ending[:40]}...")
            
            # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
            log("   [Step3] 3.3 æ•´ç†è§£è¯´æ•°æ®...")
            scenes_with_narration = []
            for seg in scene_segments:
                scene_dict = {
                    'scene_id': seg.scene_id,
                    'start_time': seg.start_time,
                    'end_time': seg.end_time,
                    'dialogue': seg.dialogue,
                    'narration': seg.narration,
                    'audio_mode': seg.audio_mode.value,  # è½¬ä¸ºå­—ç¬¦ä¸²
                    'importance': seg.importance,
                    'emotion': seg.emotion,
                    'reason': seg.reason,
                }
                # v5.6: ä¼ é€’speech_rateï¼ˆå¦‚æœæœ‰ï¼‰
                if hasattr(seg, 'speech_rate'):
                    scene_dict['speech_rate'] = seg.speech_rate
                scenes_with_narration.append(scene_dict)
            
            log(f"   [Step3]     è§£è¯´ç”Ÿæˆå®Œæˆ! å…±å¤„ç† {len(scenes_with_narration)} ä¸ªåœºæ™¯")
            
            # ========== Step 4: æ—¶é•¿æ§åˆ¶ ==========
            report_progress(4, "æ™ºèƒ½é€‰æ‹©åœºæ™¯...", "æ ¹æ®ç›®æ ‡æ—¶é•¿ç­›é€‰æœ€ä½³ç‰‡æ®µ")
            log("   [Step4] å¼€å§‹æ—¶é•¿æ§åˆ¶...")
            
            from duration_controller import DurationController
            
            log("   [Step4] 4.1 åˆå§‹åŒ–æ—¶é•¿æ§åˆ¶å™¨...")
            controller = DurationController(
                min_duration=min_duration,
                max_duration=max_duration,
                original_ratio=0.3  # è‡³å°‘30%åŸå£°
            )
            
            log("   [Step4] 4.2 ç”Ÿæˆä¼˜åŒ–æ—¶é—´çº¿...")
            timeline = controller.create_optimized_timeline(
                scenes_with_narration,
                target_duration=None  # è‡ªåŠ¨è®¡ç®—
            )
            
            # è¿‡æ»¤å¹¿å‘Šåœºæ™¯
            if detected_ads:
                try:
                    log("   [Step4] 4.3 è¿‡æ»¤å¹¿å‘Šåœºæ™¯...")
                    from ad_detector import filter_ad_segments
                    timeline = filter_ad_segments(timeline, detected_ads)
                except Exception as e:
                    log(f"   [Step4]     [WARN] å¹¿å‘Šè¿‡æ»¤è·³è¿‡: {e}")
            
            # è¿‡æ»¤è·³è¿‡çš„åœºæ™¯
            active_timeline = [t for t in timeline if t['audio_mode'] != 'skip']
            
            if not active_timeline:
                raise ValueError("æ²¡æœ‰å¯ç”¨çš„åœºæ™¯")
            
            total_duration = sum(t['duration'] for t in active_timeline)
            
            log(f"   [Step4]     é€‰æ‹©äº† {len(active_timeline)} ä¸ªåœºæ™¯")
            log(f"   [Step4]     é¢„è®¡æ—¶é•¿: {total_duration:.0f}ç§’ ({total_duration/60:.1f}åˆ†é’Ÿ)")
            
            # ä¿å­˜è§£è¯´å‰§æœ¬
            log("   [Step4] 4.4 ä¿å­˜è§£è¯´å‰§æœ¬...")
            script_path = self.work_dir / "è§£è¯´å‰§æœ¬_v5.txt"
            # v5.7.2ä¿®å¤ï¼šä½¿ç”¨æ£€æµ‹åˆ°çš„é£æ ¼åç§°è€Œä¸æ˜¯åŸå§‹style
            self._save_script(active_timeline, script_path, title, style_name)
            
            # ========== Step 5: TTSåˆ†æ®µåˆæˆ ==========
            report_progress(5, "åˆ†æ®µåˆæˆè§£è¯´é…éŸ³...", "ä½¿ç”¨Edge-TTSç”Ÿæˆè¯­éŸ³")
            log("   [Step5] å¼€å§‹TTSè¯­éŸ³åˆæˆ...")
            
            from tts_segmented import synthesize_timeline_narrations
            
            tts_dir = self.work_dir / "tts"
            voiceover_count = sum(1 for t in active_timeline if t['audio_mode'] == 'voiceover')
            log(f"   [Step5]     éœ€è¦åˆæˆ {voiceover_count} æ®µè§£è¯´éŸ³é¢‘...")
            
            narration_segments = await synthesize_timeline_narrations(
                active_timeline,
                str(tts_dir)
            )
            
            log(f"   [Step5]     TTSåˆæˆå®Œæˆ! ç”Ÿæˆ {len(narration_segments)} ä¸ªéŸ³é¢‘æ–‡ä»¶")
            
            # ========== Step 6: ç‰‡æ®µå¤„ç† ==========
            report_progress(6, "å¤„ç†è§†é¢‘ç‰‡æ®µï¼ˆåŸå£°/è§£è¯´åˆ†å¼€ï¼‰...", "è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ")
            log("   [Step6] å¼€å§‹è§†é¢‘ç‰‡æ®µå¤„ç†...")
            
            from clip_processor import process_timeline_clips, concat_processed_clips
            
            clips_dir = self.work_dir / "clips"
            
            # å¤„ç†æ¯ä¸ªç‰‡æ®µ
            log(f"   [Step6] 6.1 æå–å’Œå¤„ç† {len(active_timeline)} ä¸ªç‰‡æ®µ...")
            clip_files, clips_duration = process_timeline_clips(
                source_video=processed_video,
                timeline=active_timeline,
                narration_segments=narration_segments,
                output_dir=str(clips_dir)
            )
            log(f"   [Step6]     æå–å®Œæˆ! å…± {len(clip_files)} ä¸ªç‰‡æ®µ")
            
            # æ‹¼æ¥æ‰€æœ‰ç‰‡æ®µ
            output_video = str(self.work_dir / f"{output_name}.mp4")
            
            if not clip_files:
                raise ValueError("æ²¡æœ‰æˆåŠŸæå–ä»»ä½•è§†é¢‘ç‰‡æ®µ")
            
            log(f"   [Step6] 6.2 æ‹¼æ¥è§†é¢‘ç‰‡æ®µ...")
            concat_success = concat_processed_clips(clip_files, output_video)
            if not concat_success:
                raise RuntimeError("è§†é¢‘ç‰‡æ®µæ‹¼æ¥å¤±è´¥")
            
            log(f"   [Step6]     è§†é¢‘æ‹¼æ¥å®Œæˆ!")
            
            # ========== Step 7: è¾“å‡ºæˆå“ ==========
            report_progress(7, "ç”Ÿæˆæœ€ç»ˆæˆå“...", "æ·»åŠ å­—å¹•å’Œç”Ÿæˆç«–ç‰ˆ")
            log("   [Step7] å¼€å§‹ç”Ÿæˆæœ€ç»ˆæˆå“...")
            
            from audio_composer import add_subtitles, convert_to_vertical
            
            # æ·»åŠ å­—å¹•
            log("   [Step7] 7.1 æ·»åŠ å­—å¹•...")
            output_with_sub = str(self.work_dir / f"{output_name}_sub.mp4")
            add_subtitles(output_video, srt_path, output_with_sub)
            
            # ç”ŸæˆæŠ–éŸ³ç‰ˆ
            log("   [Step7] 7.2 ç”ŸæˆæŠ–éŸ³ç«–ç‰ˆ...")
            output_douyin = str(self.work_dir / f"{output_name}_æŠ–éŸ³.mp4")
            convert_to_vertical(output_video, output_douyin)
            log("   [Step7]     æœ€ç»ˆæˆå“ç”Ÿæˆå®Œæˆ!")
            
            # å®Œæˆ
            end_time = datetime.now()
            elapsed = (end_time - self.start_time).seconds
            
            # v5.9æ–°å¢ï¼šæœ€ç»ˆæ˜¾å­˜æŠ¥å‘Š
            if os.getenv('SMART_CLIPPER_MEMORY_REPORT', 'false').lower() == 'true':
                try:
                    from utils.gpu_manager import GPUManager
                    final_mem = GPUManager.get_memory_info()
                    if final_mem:
                        print("*" + "="*58)
                        print(f"*  [GPU] æœ€ç»ˆæ˜¾å­˜: {final_mem['used_gb']:.1f}GB/{final_mem['total_gb']:.1f}GB ({final_mem['usage_percent']:.1f}%)")
                        print("*" + "="*58)
                except Exception as e:
                    print(f"*  [GPU] æ˜¾å­˜æŠ¥å‘Šå¤±è´¥: {e}")

            print("\n" + "*"*60)
            print("*  [SUCCESS] v5.9 RTX4060æ™ºèƒ½ç®¡ç†å®Œæˆ!")
            print("*  ====================================================")
            print(f"*  ç»“æŸæ—¶é—´: {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
            print(f"*  æ€»è€—æ—¶: {elapsed//60}åˆ†{elapsed%60}ç§’")
            print(f"*  è¾“å‡ºæ–‡ä»¶: {output_video}")
            print("*  [v5.9] RTX 4060æ˜¾å­˜ä¼˜åŒ–ï¼š100%æˆåŠŸç‡ä¿è¯")
            print("*"*60 + "\n")
            
            # ç»Ÿè®¡
            orig_count = sum(1 for t in active_timeline if t['audio_mode'] == 'original')
            voice_count = sum(1 for t in active_timeline if t['audio_mode'] == 'voiceover')
            
            return {
                'success': True,
                'output_video': output_video,
                'output_douyin': output_douyin,
                'output_with_subtitle': output_with_sub,
                'script_path': str(script_path),
                'subtitle_path': srt_path,
                'duration': total_duration,
                'original_scenes': orig_count,
                'voiceover_scenes': voice_count,
                'work_dir': str(self.work_dir),
            }
            
        except Exception as e:
            print(f"\n[ERROR] å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return {
                'success': False,
                'error': str(e),
            }
    
    def _detect_emotion(self, dialogue: str) -> str:
        """æ£€æµ‹å¯¹è¯æƒ…æ„Ÿ"""
        if not dialogue:
            return 'neutral'
        
        emotion_keywords = {
            'angry': ['æ»š', 'æ··è›‹', 'å¦ˆçš„', 'æ“', 'æ€', 'æ‰“', 'æ', 'æ„¤æ€’', 'ç”Ÿæ°”', 'å»æ­»'],
            'sad': ['å“­', 'æ³ª', 'éš¾è¿‡', 'ä¼¤å¿ƒ', 'ç—›è‹¦', 'å¯¹ä¸èµ·', 'æŠ±æ­‰', 'æ‚²ä¼¤', 'æ­»äº†'],
            'happy': ['å“ˆå“ˆ', 'å¼€å¿ƒ', 'é«˜å…´', 'å¤ªå¥½äº†', 'æ£’', 'èµ', 'ç¬‘', 'å“ˆ'],
            'fear': ['æ€•', 'å®³æ€•', 'ææƒ§', 'å¯æ€•', 'å“', 'æƒŠ', 'æ•‘å‘½'],
            'excited': ['æ¿€åŠ¨', 'å…´å¥‹', 'å¤ªæ£’äº†', 'ä¸æ•¢ç›¸ä¿¡', 'å¤©å“ª'],
        }
        
        for emotion, keywords in emotion_keywords.items():
            if any(kw in dialogue for kw in keywords):
                return emotion
        
        return 'neutral'
    
    def _save_script(self, timeline: List[Dict], path: Path, title: str, style_name: str):
        """ä¿å­˜è§£è¯´å‰§æœ¬ v5.7.2"""
        lines = []
        lines.append("=" * 60)
        lines.append(f"SmartVideoClipper v5.8.0 - Structuredè§£è¯´å‰§æœ¬")
        lines.append(f"ä½œå“: {title}")
        lines.append(f"é£æ ¼: {style_name}")
        lines.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append("=" * 60)
        lines.append("")
        lines.append("æ ¸å¿ƒæ”¹è¿›ï¼š")
        lines.append("  1. æ¯ä¸ªç‰‡æ®µç‹¬ç«‹å¤„ç†éŸ³é¢‘ï¼ˆåŸå£°/è§£è¯´åˆ†å¼€ï¼‰")
        lines.append("  2. TTSåˆ†æ®µç”Ÿæˆï¼ˆè§£è¯´-ç”»é¢ç²¾ç¡®å¯¹é½ï¼‰")
        lines.append("  3. æ™ºèƒ½æ—¶é•¿æ§åˆ¶")
        lines.append("")
        lines.append("=" * 60)
        lines.append("")
        
        for i, item in enumerate(timeline, 1):
            mode = "[åŸå£°]" if item['audio_mode'] == 'original' else "[è§£è¯´]"
            lines.append(f"ã€åœºæ™¯ {i}ã€‘ {mode}")
            lines.append(f"æ—¶é—´: {item['source_start']:.1f}s - {item['source_end']:.1f}s ({item['duration']:.1f}ç§’)")
            lines.append(f"é‡è¦æ€§: {item['importance']:.2f}")
            
            if item.get('dialogue'):
                lines.append(f"å¯¹ç™½: {item['dialogue'][:100]}...")
            
            if item.get('narration') and item['audio_mode'] == 'voiceover':
                lines.append(f"è§£è¯´: {item['narration']}")
            
            if item.get('reason'):
                lines.append(f"åŸå› : {item['reason']}")
            
            lines.append("")
        
        # ç»Ÿè®¡
        orig_count = sum(1 for t in timeline if t['audio_mode'] == 'original')
        voice_count = sum(1 for t in timeline if t['audio_mode'] == 'voiceover')
        total_duration = sum(t['duration'] for t in timeline)
        
        lines.append("=" * 60)
        lines.append("ç»Ÿè®¡:")
        lines.append(f"  æ€»åœºæ™¯: {len(timeline)}")
        lines.append(f"  åŸå£°åœºæ™¯: {orig_count} ({orig_count*100//(orig_count+voice_count+1)}%)")
        lines.append(f"  è§£è¯´åœºæ™¯: {voice_count} ({voice_count*100//(orig_count+voice_count+1)}%)")
        lines.append(f"  æ€»æ—¶é•¿: {total_duration:.0f}ç§’ ({total_duration/60:.1f}åˆ†é’Ÿ)")
        lines.append("=" * 60)
        
        with open(path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(lines))
        
        print(f"   âœ“ å‰§æœ¬å·²ä¿å­˜: {path}")


async def run_v5(
    video_path: str,
    output_name: str,
    title: str = "",
    style: str = "å¹½é»˜",
    min_duration: int = 180,
    max_duration: int = 900,
    media_type: str = "auto",  # ğŸ†• åª’ä½“ç±»å‹ (auto/tv/movie)
    episode: int = 0           # ğŸ†• é›†æ•°/éƒ¨æ•°
) -> Dict:
    """
    è¿è¡Œ v5.1 æµæ°´çº¿
    
    è¿™æ˜¯å¯¹å¤–çš„ä¸»å…¥å£
    
    å‚æ•°ï¼š
        video_path: è§†é¢‘è·¯å¾„
        output_name: è¾“å‡ºåç§°
        title: ä½œå“åç§°
        style: è§£è¯´é£æ ¼
        min_duration: æœ€çŸ­æ—¶é•¿ï¼ˆç§’ï¼‰
        max_duration: æœ€é•¿æ—¶é•¿ï¼ˆç§’ï¼‰
        media_type: åª’ä½“ç±»å‹ (autoè‡ªåŠ¨/tvç”µè§†å‰§/movieç”µå½±)
        episode: é›†æ•°/éƒ¨æ•°ï¼ˆ0=è‡ªåŠ¨ä»æ–‡ä»¶åè§£æï¼‰
    """
    pipeline = VideoPipelineV5()
    return await pipeline.process(
        video_path=video_path,
        output_name=output_name,
        title=title,
        style=style,
        min_duration=min_duration,
        max_duration=max_duration,
        media_type=media_type,
        episode=episode
    )


# æµ‹è¯•å…¥å£
if __name__ == "__main__":
    import asyncio
    
    async def test():
        result = await run_v5(
            video_path=r"C:\Users\Administrator\Downloads\ç‹‚é£™E01.mp4",
            output_name="ç‹‚é£™ç¬¬ä¸€é›†_v5",
            title="ç‹‚é£™",
            style="å¹½é»˜"
        )
        print(result)
    
    asyncio.run(test())
