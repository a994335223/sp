# core/movie_info.py - è”ç½‘è·å–ç”µå½±ä¿¡æ¯ï¼ˆå›½å†…ç‰ˆ-è±†ç“£ï¼‰
"""
SmartVideoClipper - ç”µå½±ä¿¡æ¯è·å–æ¨¡å—

åŠŸèƒ½: ä»è±†ç“£è·å–ç”µå½±ä¿¡æ¯ï¼ˆè¯„åˆ†ã€æ¼”å‘˜ã€å‰§æƒ…ç®€ä»‹ï¼‰
ç”¨é€”: å¢å¼ºAIæ–‡æ¡ˆç”Ÿæˆçš„èƒŒæ™¯çŸ¥è¯†

ä¾èµ–: httpx, beautifulsoup4
"""

import httpx
from bs4 import BeautifulSoup
import re
import time
import random


class MovieInfoFetcher:
    """
    ğŸ‡¨ğŸ‡³ å›½å†…ç‰ˆï¼šä½¿ç”¨è±†ç“£è·å–ç”µå½±ä¿¡æ¯
    âœ… æ— éœ€VPNï¼Œå›½å†…ç›´æ¥è®¿é—®
    âœ… æ— éœ€API Key
    âœ… æ•°æ®æ›´è´´åˆå›½å†…ç”¨æˆ·ä¹ æƒ¯
    âš ï¸ åŒ…å«å®Œå–„çš„åçˆ¬è™«å¤„ç†
    """
    
    def __init__(self):
        # ğŸ”§ æ›´å®Œå–„çš„è¯·æ±‚å¤´ï¼Œæ¨¡æ‹ŸçœŸå®æµè§ˆå™¨
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
            "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
            "Accept-Encoding": "gzip, deflate, br",
            "Connection": "keep-alive",
            "Referer": "https://www.douban.com/"
        }
        self.max_retries = 3
    
    def search_movie(self, movie_name: str) -> dict:
        """
        æœç´¢ç”µå½±ä¿¡æ¯ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
        
        å‚æ•°:
            movie_name: ç”µå½±åç§°
        
        è¿”å›:
            {
                'title': 'ç”µå½±å',
                'rating': '8.5/10 (è±†ç“£)',
                'director': 'å¯¼æ¼”',
                'cast': ['æ¼”å‘˜1', 'æ¼”å‘˜2', ...],
                'genres': ['åŠ¨ä½œ', 'ç§‘å¹»'],
                'overview': 'å‰§æƒ…ç®€ä»‹',
                'source': 'è±†ç“£'
            }
        """
        for attempt in range(self.max_retries):
            try:
                # ğŸ”§ æ·»åŠ éšæœºå»¶è¿Ÿï¼Œé¿å…è¢«å°
                if attempt > 0:
                    delay = random.uniform(2, 5)
                    print(f"   ç¬¬{attempt+1}æ¬¡é‡è¯•ï¼Œç­‰å¾…{delay:.1f}ç§’...")
                    time.sleep(delay)
                
                return self._search_douban(movie_name)
            except Exception as e:
                print(f"âš ï¸ è±†ç“£æœç´¢å¤±è´¥ (å°è¯• {attempt+1}/{self.max_retries}): {e}")
                if attempt == self.max_retries - 1:
                    return {"title": movie_name, "overview": "", "error": str(e)}
        
        return {"title": movie_name, "overview": ""}
    
    def _search_douban(self, movie_name: str) -> dict:
        """ä½¿ç”¨è±†ç“£æœç´¢ï¼ˆå›½å†…å¯ç›´æ¥è®¿é—®ï¼‰"""
        # ğŸ”§ æ·»åŠ éšæœºå»¶è¿Ÿ
        time.sleep(random.uniform(0.5, 1.5))
        
        with httpx.Client(headers=self.headers, timeout=15, follow_redirects=True) as client:
            # 1. æœç´¢ç”µå½±
            search_url = "https://www.douban.com/search"
            params = {"q": movie_name, "cat": "1002"}  # cat=1002æ˜¯ç”µå½±
            resp = client.get(search_url, params=params)
            soup = BeautifulSoup(resp.text, "html.parser")
            
            # æ‰¾åˆ°ç¬¬ä¸€ä¸ªç”µå½±ç»“æœ
            result = soup.select_one(".result-list .result h3 a")
            if not result:
                return {"title": movie_name, "overview": "æœªæ‰¾åˆ°"}
            
            # æå–è±†ç“£ç”µå½±ID
            onclick = result.get("onclick", "")
            sid_match = re.search(r"sid:\s*(\d+)", onclick)
            if sid_match:
                movie_id = sid_match.group(1)
                movie_url = f"https://movie.douban.com/subject/{movie_id}/"
            else:
                movie_url = result.get("href")
            
            # 2. è·å–ç”µå½±è¯¦æƒ…é¡µ
            time.sleep(random.uniform(0.5, 1))  # å†æ¬¡å»¶è¿Ÿ
            resp = client.get(movie_url)
            soup = BeautifulSoup(resp.text, "html.parser")
            
            # è§£ææ ‡é¢˜
            title_elem = soup.select_one("h1 span")
            title = title_elem.text.strip() if title_elem else movie_name
            
            # è§£æè¯„åˆ†
            rating_elem = soup.select_one(".rating_num")
            rating = rating_elem.text.strip() if rating_elem else "N/A"
            
            # è§£æè¯¦ç»†ä¿¡æ¯
            info_elem = soup.select_one("#info")
            info_text = info_elem.text if info_elem else ""
            
            # å¯¼æ¼”
            director_match = re.search(r"å¯¼æ¼”:\s*([^\n]+)", info_text)
            director = director_match.group(1).strip().split("/")[0] if director_match else "N/A"
            
            # ä¸»æ¼”
            cast_match = re.search(r"ä¸»æ¼”:\s*([^\n]+)", info_text)
            cast = []
            if cast_match:
                cast = [c.strip() for c in cast_match.group(1).split("/")[:5]]
            
            # ç±»å‹
            genre_match = re.search(r"ç±»å‹:\s*([^\n]+)", info_text)
            genres = genre_match.group(1).strip().split() if genre_match else []
            
            # ç®€ä»‹
            summary_elem = soup.select_one('[property="v:summary"]')
            summary = summary_elem.text.strip() if summary_elem else ""
            
            return {
                "title": title,
                "rating": f"{rating}/10 (è±†ç“£)",
                "director": director,
                "cast": cast,
                "genres": genres,
                "overview": summary[:500],
                "source": "è±†ç“£"
            }


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    fetcher = MovieInfoFetcher()
    
    # æµ‹è¯•æœç´¢
    test_movies = ["å¤ä»‡è€…è”ç›Ÿ", "æµæµªåœ°çƒ", "å“ªå’ä¹‹é­”ç«¥é™ä¸–"]
    
    for movie in test_movies:
        print(f"\næœç´¢: {movie}")
        print("-" * 40)
        info = fetcher.search_movie(movie)
        
        if "error" not in info:
            print(f"ğŸ¬ ç”µå½±: {info['title']}")
            print(f"â­ è¯„åˆ†: {info['rating']}")
            print(f"ğŸ¬ å¯¼æ¼”: {info['director']}")
            print(f"ğŸ‘¥ ä¸»æ¼”: {', '.join(info['cast'][:3])}")
            print(f"ğŸ·ï¸ ç±»å‹: {', '.join(info['genres'])}")
            print(f"ğŸ“– ç®€ä»‹: {info['overview'][:100]}...")
        else:
            print(f"âŒ æœç´¢å¤±è´¥: {info.get('error')}")

