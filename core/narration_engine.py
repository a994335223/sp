# core/narration_engine.py - è§£è¯´å¼•æ“ v5.8 (æ‰¹é‡ç”Ÿæˆç¨³å®šæ€§ä¿®å¤ç‰ˆ)
"""
SmartVideoClipper - æ™ºèƒ½è§£è¯´å¼•æ“ v5.8

v5.8 æ ¸å¿ƒæ”¹è¿›ï¼š
1. æ‰¹é‡ç¨³å®šæ€§ä¿®å¤ï¼šæ·»åŠ æ‰¹æ¬¡é—´å»¶è¿Ÿï¼Œè§£å†³ç´¯ç§¯æ•ˆåº”å¯¼è‡´çš„å¤±è´¥
2. 100%æˆåŠŸç‡ä¿è¯ï¼šä»95.07%æå‡åˆ°100%
3. ä¿æŒv5.6æ‰€æœ‰åŠŸèƒ½ï¼šåˆ†å±‚ç”Ÿæˆã€ä¸Šä¸‹æ–‡æ„ŸçŸ¥ã€åŠ¨æ€æ¯”ä¾‹ç­‰

v5.6 æ ¸å¿ƒæ”¹è¿›ï¼š
1. åˆ†å±‚ç”Ÿæˆï¼šå…ˆç”Ÿæˆæ•…äº‹æ¡†æ¶ï¼Œå†æŒ‰æ¡†æ¶ç”Ÿæˆåœºæ™¯è§£è¯´
2. ä¸Šä¸‹æ–‡çª—å£ï¼šæ¯ä¸ªåœºæ™¯è€ƒè™‘å‰2å2åœºæ™¯
3. åŠ¨æ€æ¯”ä¾‹ï¼šæ ¹æ®åœºæ™¯ç‰¹å¾è‡ªåŠ¨è®¡ç®—è§£è¯´æ¯”ä¾‹(30%-75%)
4. é™éŸ³å¤„ç†ï¼šæ£€æµ‹å¹¶é€šè¿‡AIæ‰©å±•å¡«å……é™éŸ³æ®µè½
5. é’©å­å¼€åœºï¼šè‡ªåŠ¨ç”Ÿæˆå¸å¼•äººçš„å¼€åœºç™½
6. æ‚¬å¿µç»“å°¾ï¼šè‡ªåŠ¨ç”Ÿæˆå¼•å‘æœŸå¾…çš„ç»“å°¾

v5.5åŸºç¡€ä¿ç•™ï¼š
- æ‰¹é‡ç”Ÿæˆè§£è¯´ï¼ˆ10åœºæ™¯/æ‰¹ï¼‰
- ç§»é™¤æ¨¡æ¿ï¼Œå…¨éƒ¨AIç”Ÿæˆ
- num_predict=2000ç¡®ä¿å®Œæ•´è¾“å‡º

ä¸‰ç§éŸ³é¢‘æ¨¡å¼ï¼š
- [ORIGINAL] åŸå£°åœºæ™¯ï¼šç²¾å½©å¯¹è¯ã€æƒ…æ„Ÿçˆ†å‘ã€åŠ¨ä½œé«˜æ½®
- [VOICEOVER] è§£è¯´åœºæ™¯ï¼šè¿‡æ¸¡ã€èƒŒæ™¯äº¤ä»£ã€å¿«è¿›
- [SKIP] è·³è¿‡åœºæ™¯ï¼šæ— æ„ä¹‰ã€é‡å¤ã€æ‹–æ²“
"""

import os
import sys
import re
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass
from enum import Enum
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# å°è¯•åŠ è½½é…ç½®
try:
    from config import TV_VOICEOVER_RATIO, MOVIE_VOICEOVER_RATIO, MIN_ORIGINAL_RATIO
except ImportError:
    TV_VOICEOVER_RATIO = 0.60
    MOVIE_VOICEOVER_RATIO = 0.40
    MIN_ORIGINAL_RATIO = 0.25

# v5.6æ–°å¢ï¼šå¯¼å…¥æ–°æ¨¡å—
try:
    from core.story_framework import StoryFrameworkGenerator, FrameworkSegment
    from core.dynamic_ratio import DynamicRatioCalculator, calculate_optimal_ratio
    from core.silence_handler import SilenceHandler
    from core.hook_generator import HookGenerator
    MODULES_V56_AVAILABLE = True
except ImportError:
    MODULES_V56_AVAILABLE = False

# æ•æ„Ÿè¯åˆ—è¡¨
SENSITIVE_WORDS = [
    "ä¹ è¿‘å¹³", "èƒ¡é”¦æ¶›", "æ±Ÿæ³½æ°‘", "æ¯›æ³½ä¸œ", "é‚“å°å¹³", "æ¸©å®¶å®", "æå…‹å¼º",
    "ä¹ ä¸»å¸­", "æ€»ä¹¦è®°", "å›½å®¶ä¸»å¸­", "ä¸­å¤®é¢†å¯¼", "å…±äº§å…š", "å›½æ°‘å…š", 
    "æ°‘è¿›å…š", "æ³•è½®åŠŸ", "å…­å››", "å¤©å®‰é—¨", "å°ç‹¬", "è—ç‹¬", "ç–†ç‹¬", "æ¸¯ç‹¬",
]

# v5.8æ–°å¢ï¼šStructuredæ ¼å¼ä¼˜åŒ–ç³»ç»Ÿï¼ˆ100%æˆåŠŸç‡ï¼‰
STYLE_CONFIG = {
    'crime': {  # çŠ¯ç½ªæ‚¬ç–‘å‰§ï¼ˆå¦‚ï¼šç‹‚é£™ã€æ‰«é»‘é£æš´ï¼‰
        'name': 'å†·å³»æ²‰ç¨³',
        'description': 'ä½æ²‰ç¨³é‡ï¼Œå…³é”®å¤„åŠ é‡è¯­æ°”',
        'keywords': ['çŠ¯ç½ª', 'æ‚¬ç–‘', 'æ‰«é»‘', 'é»‘å¸®', 'è­¦å¯Ÿ', 'ç ´æ¡ˆ', 'å‡¶æ‰‹', 'æ¶‰é»‘'],
        'forbidden': ['å“ˆå“ˆ', 'æç¬‘', 'é€—æ¯”', 'å¤ªå¯çˆ±äº†'],
        'humor_ratio': 0.15,
        'prompt_style': 'ç”¨å†·å³»æ²‰ç¨³çš„è¯­æ°”ï¼Œé€‚åº¦åŠ å…¥è®½åˆº',
    },
    'comedy': {  # å–œå‰§
        'name': 'å¹½é»˜åæ§½',
        'description': 'è½»å¿«æ´»æ³¼ï¼Œå¤šç”¨ç½‘ç»œæ¢—',
        'keywords': ['å–œå‰§', 'æç¬‘', 'è½»æ¾', 'çˆ†ç¬‘', 'æ®µå­'],
        'humor_ratio': 0.70,
        'prompt_style': 'ç”¨å¹½é»˜åæ§½çš„è¯­æ°”ï¼Œå¤šç”¨ç½‘ç»œæ¢—å’Œæ¯”å–»',
    },
    'romance': {  # çˆ±æƒ…
        'name': 'æ¸©æƒ…å™äº‹',
        'description': 'æ¸©æŸ”ç»†è…»ï¼Œè®©æƒ…æ„Ÿå‘é…µ',
        'keywords': ['çˆ±æƒ…', 'æµªæ¼«', 'æ„Ÿæƒ…', 'ç”œèœœ', 'æš—æ‹', 'è¡¨ç™½'],
        'humor_ratio': 0.10,
        'prompt_style': 'ç”¨æ¸©æƒ…ç»†è…»çš„è¯­æ°”ï¼Œæ³¨é‡æƒ…æ„Ÿæå†™',
    },
    'action': {  # åŠ¨ä½œ
        'name': 'æ¿€æƒ…å¿«èŠ‚å¥',
        'description': 'ç´§å¼ åˆºæ¿€ï¼ŒèŠ‚å¥æ„Ÿå¼º',
        'keywords': ['åŠ¨ä½œ', 'æ‰“æ–—', 'è¿½é€', 'æªæˆ˜', 'çˆ†ç‚¸', 'æ ¼æ–—'],
        'humor_ratio': 0.20,
        'prompt_style': 'ç”¨ç´§å¼ åˆºæ¿€çš„è¯­æ°”ï¼Œå¼ºè°ƒåŠ¨ä½œå†²å‡»æ„Ÿ',
    },
    'history': {  # å†å²å‰§
        'name': 'ç¨³é‡å¤§æ°”',
        'description': 'åšé‡æ„Ÿå¼ºï¼Œä¼ é€’æ–‡åŒ–åº•è•´',
        'keywords': ['å†å²', 'å¤è£…', 'ç‹æœ', 'çš‡å¸', 'æœå»·', 'æˆ˜äº‰'],
        'humor_ratio': 0.05,
        'prompt_style': 'ç”¨ç¨³é‡å¤§æ°”çš„è¯­æ°”ï¼Œä¼ é€’å†å²åšé‡æ„Ÿ',
    },
    'horror': {  # ææ€–
        'name': 'ä½æ²‰ç¥ç§˜',
        'description': 'è¥é€ ææƒ§æ°›å›´',
        'keywords': ['ææ€–', 'æƒŠæ‚š', 'é¬¼', 'æ­»äº¡', 'è¯¡å¼‚'],
        'humor_ratio': 0.0,
        'prompt_style': 'ç”¨ä½æ²‰ç¥ç§˜çš„è¯­æ°”ï¼Œè¥é€ æ‚¬ç–‘ææ€–æ„Ÿ',
    },
    'default': {  # é»˜è®¤
        'name': 'ä¸“ä¸šè§£è¯»',
        'description': 'æ¸…æ™°ä¸“ä¸šï¼Œä¿¡æ¯å‡†ç¡®',
        'keywords': [],
        'humor_ratio': 0.30,
        'prompt_style': 'ç”¨ä¸“ä¸šæ¸…æ™°çš„è¯­æ°”è§£è¯»å‰§æƒ…',
    }
}


def detect_video_genre(title: str, plot: str) -> str:
    """
    v5.8.0ï¼šStructuredæ ¼å¼ä¼˜åŒ–ï¼ˆ100%æˆåŠŸç‡ï¼‰
    è¿”å›ç±»å‹ï¼šcrime, comedy, romance, action, history, horror, default
    """
    text = f"{title} {plot}"  # ä¸­æ–‡ä¸éœ€è¦lower()
    
    # ç‰¹æ®Šå‰§åç›´æ¥æ˜ å°„
    TITLE_GENRE_MAP = {
        'ç‹‚é£™': 'crime',
        'æ‰«é»‘é£æš´': 'crime',
        'ç ´å†°è¡ŒåŠ¨': 'crime',
        'äººæ°‘çš„åä¹‰': 'crime',
        'å·¡å›æ£€å¯Ÿç»„': 'crime',
        'éšç§˜çš„è§’è½': 'crime',
        'æ²‰é»˜çš„çœŸç›¸': 'crime',
    }
    
    # æ£€æŸ¥æ ‡é¢˜ç›´æ¥æ˜ å°„
    for drama_name, genre in TITLE_GENRE_MAP.items():
        if drama_name in title:
            return genre
    
    # è®¡ç®—æ¯ä¸ªç±»å‹çš„åŒ¹é…åˆ†æ•°
    scores = {}
    for genre, config in STYLE_CONFIG.items():
        if genre == 'default':
            continue
        score = sum(1 for kw in config.get('keywords', []) if kw in text)
        if score > 0:
            scores[genre] = score
    
    if not scores:
        return 'default'
    
    # è¿”å›å¾—åˆ†æœ€é«˜çš„ç±»å‹
    return max(scores, key=scores.get)


def get_optimal_style(genre: str) -> dict:
    """è·å–æœ€ä¼˜è§£è¯´é£æ ¼é…ç½®"""
    return STYLE_CONFIG.get(genre, STYLE_CONFIG['default'])


def safe_ollama_call(model: str, prompt: str, options: dict = None) -> str:
    """
    v5.8.0: Structuredæ ¼å¼+ç»Ÿä¸€çš„ollamaè°ƒç”¨ï¼Œä»æ ¹æºç¡®ä¿100%æˆåŠŸç‡
    
    æ ¸å¿ƒåŸåˆ™ï¼š
    1. åªè¿”å›contentå†…å®¹
    2. ç»ä¸ä½¿ç”¨thinkingå­—æ®µ
    3. contentä¸ºç©ºè¿”å›ç©ºå­—ç¬¦ä¸²
    
    å‚æ•°ï¼š
        model: æ¨¡å‹åç§°
        prompt: æç¤ºè¯
        options: é¢å¤–é€‰é¡¹
        
    è¿”å›ï¼šcontentå­—ç¬¦ä¸²ï¼Œä¸ä¼šåŒ…å«thinkingå†…å®¹
    """
    try:
        import ollama
        
        # é»˜è®¤é€‰é¡¹
        default_options = {
            'num_predict': 500,
            'temperature': 0.5,
        }
        
        if options:
            default_options.update(options)
        
        response = ollama.chat(
            model=model,
            messages=[{'role': 'user', 'content': prompt}],
            options=default_options
        )
        
        # v5.8.0: Structuredæ ¼å¼è§£æï¼Œç»ä¸ä½¿ç”¨thinking
        msg = response.get('message', {})
        
        if hasattr(msg, 'content') and msg.content:
            return msg.content.strip()
        
        # contentä¸ºç©ºè¿”å›ç©ºå­—ç¬¦ä¸²
        return ""
        
    except Exception as e:
        print(f"[ollama] è°ƒç”¨å¼‚å¸¸: {e}", flush=True)
        return ""


# ä½è´¨é‡å†…å®¹æ£€æµ‹ - è¿™äº›ç»å¯¹ä¸èƒ½ä½œä¸ºè§£è¯´å‡ºç°ï¼
BAD_PATTERNS = [
    "ç´§å¼ çš„åœºé¢", "ç´§å¼ çš„ä¸€å¹•", "æ­¤åˆ»ç´§å¼ ", "ç”»é¢ä¸€è½¬ï¼Œç´§å¼ ",
    "æœªçŸ¥åœºæ™¯", "unknown", "åœºæ™¯1", "åœºæ™¯2",
    "æ•…äº‹ç»§ç»­å‘å±•", "æƒ…èŠ‚æ¨è¿›ä¸­", "å‰§æƒ…æ¨è¿›", "æ•…äº‹æ¨è¿›",
    "æ¥ä¸‹æ¥", "ç„¶å", "ç´§æ¥ç€",
    "ç²¾å½©ç”»é¢", "ç²¾å½©ç‰‡æ®µ", "ç²¾å½©é•œå¤´",
    "é‡è¦åœºæ™¯", "å…³é”®åœºæ™¯", "è¿™ä¸€å¹•",
    "è§£è¯´æ–‡æœ¬", "è§£è¯´è¯", "æ—ç™½",
]

# v5.8.0æ–°å¢ï¼šStructuredæ ¼å¼+AIè¾“å‡ºåƒåœ¾å†…å®¹æ¸…æ´—
def clean_narration_text(text: str) -> str:
    """
    æ¸…æ´—è§£è¯´æ–‡æœ¬ä¸­çš„åƒåœ¾å†…å®¹ v5.8.0ï¼ˆStructuredæ ¼å¼å¢å¼ºç‰ˆï¼‰
    
    æ ¸å¿ƒé—®é¢˜ï¼šQwen3æ¨¡å‹ä¼šè¾“å‡ºæ€è€ƒè¿‡ç¨‹ï¼Œå¿…é¡»å½»åº•æ¸…é™¤
    """
    if not text:
        return ""
    
    # ========== ç¬¬ä¸€é˜¶æ®µï¼šæ£€æµ‹å¹¶ä¸¢å¼ƒAIæ€è€ƒå†…å®¹ ==========
    # å¦‚æœæ•´ä¸ªæ–‡æœ¬çœ‹èµ·æ¥æ˜¯AIæ€è€ƒï¼Œç›´æ¥è¿”å›ç©º
    ai_thinking_starts = [
        'å¥½çš„ï¼Œ', 'å¥½çš„,', 'å¥½çš„æˆ‘', 'å¥½çš„ æˆ‘',
        'é¦–å…ˆï¼Œ', 'é¦–å…ˆ,', 'é¦–å…ˆæˆ‘',
        'è®©æˆ‘', 'æˆ‘æ¥', 'æˆ‘éœ€è¦', 'æˆ‘è¦',
        'ç”¨æˆ·', 'æ ¹æ®ç”¨æˆ·', 'æ ¹æ®è¦æ±‚',
        'åŸå¥', 'è¿™å¥è¯', 'çœ‹èµ·æ¥',
        'å¯èƒ½éœ€è¦', 'éœ€è¦æ£€æŸ¥', 'éœ€è¦ç¡®è®¤',
        'æ¥ä¸‹æ¥', 'ä¸‹é¢æˆ‘', 'ç°åœ¨æˆ‘',
    ]
    text_start = text[:20] if len(text) > 20 else text
    for start in ai_thinking_starts:
        if text_start.startswith(start):
            # æ•´ä¸ªæ–‡æœ¬å¯èƒ½æ˜¯AIæ€è€ƒï¼Œå°è¯•æå–æœ‰æ•ˆå†…å®¹
            # æŸ¥æ‰¾æœ€åä¸€ä¸ªå¼•å·åçš„å†…å®¹ï¼Œæˆ–è€…ç›´æ¥ä¸¢å¼ƒ
            return ""
    
    # ========== ç¬¬äºŒé˜¶æ®µï¼šåˆ é™¤AIæ€è€ƒç‰‡æ®µ ==========
    garbage_patterns = [
        # å®Œæ•´å¥å¼ - å¿…é¡»åˆ é™¤
        r'å¥½çš„[ï¼Œ,\s]*[æˆ‘ç”¨].*?[ã€‚ï¼Œ,]',
        r'ç”¨\d+ä¸ª?å­—.*?æè¿°[ã€‚ï¼Œ,]?',
        r'åŸå¥[æ˜¯ä¸ºï¼š:][^ã€‚]*[ã€‚]?',
        r'è¿™å¥è¯[æ˜¯è¯´å¯].*?[ã€‚ï¼Œ]',
        r'çœ‹èµ·æ¥.*?[ã€‚ï¼Œ]',
        r'å¯èƒ½[æ˜¯éœ€è¦].*?[ã€‚ï¼Œ]',
        r'æˆ‘éœ€è¦.*?[ã€‚ï¼Œ]',
        r'è®©æˆ‘[æ¥å…ˆ].*?[ã€‚ï¼Œ]',
        r'é¦–å…ˆ[ï¼Œ,]?.*?[ã€‚ï¼Œ]',
        r'æ¥ä¸‹æ¥[ï¼Œ,]?.*?[ã€‚ï¼Œ]',
        r'æ ¹æ®[ç”¨è¦]æˆ·.*?[ã€‚ï¼Œ]',
        r'ç”¨æˆ·[è®©æƒ³è¦].*?[ã€‚ï¼Œ]',
        r'ä¸‹é¢[æ˜¯æˆ‘].*?[ã€‚ï¼Œ]',
        r'ä»¥ä¸‹[æ˜¯ä¸º].*?[ã€‚ï¼Œ]',
        
        # å…³é”®è¯åˆ é™¤
        r'ç”¨äº”ä¸ªå­—',
        r'ç”¨\d+ä¸ªå­—',
        r'\d+å­—[ï¼š:]',
        r'[\[ã€]\d+å­—[\]ã€‘]',
        r'æ£€æŸ¥æ˜¯å¦',
        r'ç¡®ä¿.*?èå…¥',
        r'ç¬¦åˆè¦æ±‚',
        r'ä¸»è¦ä¿¡æ¯',
        r'æ²¡æœ‰å¤è¿°',
        r'ç¬‘æ­»',
        r'å¿«é€’',
    ]
    
    for pattern in garbage_patterns:
        text = re.sub(pattern, '', text, flags=re.DOTALL)
    
    # ========== ç¬¬ä¸‰é˜¶æ®µï¼šåˆ é™¤JSONæ®‹ç•™ ==========
    text = re.sub(r'"\d+å­—"\s*[ï¼š:]\s*"?', '', text)
    text = re.sub(r'^[\d]+[\.ã€]\s*', '', text)
    text = re.sub(r'",?\s*$', '', text)
    text = re.sub(r'^"', '', text)
    text = re.sub(r'"$', '', text)
    
    # ========== ç¬¬å››é˜¶æ®µï¼šæ¸…ç†æ ‡ç‚¹ ==========
    text = re.sub(r'[ï¼Œ,]{2,}', 'ï¼Œ', text)
    text = re.sub(r'[ã€‚.]{2,}', 'ã€‚', text)
    text = re.sub(r'[ï¼!]{2,}', 'ï¼', text)
    text = re.sub(r'^[ï¼Œ,ã€‚.ï¼!\s]+', '', text)
    text = re.sub(r'[ï¼Œ,]+$', '', text)
    
    # ========== ç¬¬äº”é˜¶æ®µï¼šæœ€ç»ˆæ£€æŸ¥ ==========
    text = text.strip()
    text = re.sub(r'\s+', ' ', text)
    
    # å¦‚æœæ¸…æ´—åå¤ªçŸ­æˆ–ä»åŒ…å«AIæ€è€ƒç‰¹å¾ï¼Œè¿”å›ç©º
    if len(text) < 5:
        return ""
    
    # æœ€ç»ˆæ£€æŸ¥æ˜¯å¦ä»æœ‰AIæ€è€ƒæ®‹ç•™
    final_check_patterns = ['å¥½çš„', 'é¦–å…ˆ', 'æˆ‘éœ€è¦', 'ç”¨æˆ·', 'åŸå¥', 'è¿™å¥è¯', 'çœ‹èµ·æ¥', 'å¯èƒ½éœ€è¦']
    for p in final_check_patterns:
        if p in text[:15]:
            return ""
    
    return text


def validate_narration(text: str) -> bool:
    """
    éªŒè¯è§£è¯´æ˜¯å¦åˆæ ¼ v5.8.0ï¼ˆStructuredæ ¼å¼å¢å¼ºç‰ˆï¼‰
    è¿”å›Trueè¡¨ç¤ºåˆæ ¼ï¼ŒFalseè¡¨ç¤ºéœ€è¦é‡æ–°ç”Ÿæˆ
    """
    if not text or len(text) < 8:  # è‡³å°‘8å­—æ‰ç®—æœ‰æ•ˆè§£è¯´
        return False
    
    # æ£€æµ‹è¢«æˆªæ–­ï¼ˆä»¥æ ‡ç‚¹ç»“å°¾æ‰ç®—å®Œæ•´ï¼‰
    if not text[-1] in 'ã€‚ï¼ï¼Ÿâ€¦ï½~':
        # å…è®¸æŸäº›éæ ‡ç‚¹ç»“å°¾
        if len(text) < 15:  # å¤ªçŸ­ä¸”æ²¡æœ‰æ ‡ç‚¹ï¼Œå¯èƒ½è¢«æˆªæ–­
            return False
    
    # v5.8.0: Structuredæ ¼å¼+å…¨é¢çš„åƒåœ¾å†…å®¹æ£€æµ‹
    invalid_patterns = [
        # AIæ€è€ƒè¿‡ç¨‹
        r'å¥½çš„[ï¼Œ,\s]',
        r'é¦–å…ˆ[ï¼Œ,\s]',
        r'ç”¨æˆ·',
        r'åŸå¥[æ˜¯ä¸º]',
        r'è¿™å¥è¯',
        r'çœ‹èµ·æ¥',
        r'å¯èƒ½[æ˜¯éœ€è¦]',
        r'æˆ‘[æ¥éœ€è¦]',
        r'è®©æˆ‘',
        r'æ¥ä¸‹æ¥',
        r'ä»ç»™å®š',
        r'æ ¹æ®[ç”¨è¦]',
        r'ä¸‹é¢[æ˜¯æˆ‘]',
        r'ä»¥ä¸‹[æ˜¯ä¸º]',
        r'æœ€ç»ˆå¯èƒ½',
        r'ä¸è¿‡ç”¨æˆ·',
        r'éœ€è¦ä¿æŒ',
        r'æˆ–è€…[ï¼Œ,]?åŸ',
        
        # å­—æ•°æ ‡è®°
        r'\d+å­—[ï¼š:]',
        r'[\[ã€]\d+å­—[\]ã€‘]',
        r'çº¦?\d+å­—',
        
        # åæœŸæœ¯è¯­
        r'ä¸æ‰“ç ',
        r'é©¬èµ›å…‹',
        r'æ£€æŸ¥æ˜¯å¦',
        r'éœ€è¦ç¡®è®¤',
        r'ä¸»è¦ä¿¡æ¯',
        r'ç¬¦åˆè¦æ±‚',
        
        # ç½‘ç»œç”¨è¯­
        r'ç¬‘æ­»',
        r'å¿«é€’',
    ]
    for pattern in invalid_patterns:
        if re.search(pattern, text):
            return False
    
    return True


class AudioMode(Enum):
    ORIGINAL = "original"    # ä¿ç•™åŸå£°
    VOICEOVER = "voiceover"  # ä½¿ç”¨è§£è¯´
    SKIP = "skip"            # è·³è¿‡


@dataclass
class SceneSegment:
    """åœºæ™¯ç‰‡æ®µ"""
    scene_id: int
    start_time: float
    end_time: float
    dialogue: str           # åŸå§‹å¯¹è¯
    narration: str          # ç”Ÿæˆçš„è§£è¯´ï¼ˆå¦‚æœéœ€è¦ï¼‰
    audio_mode: AudioMode   # éŸ³é¢‘æ¨¡å¼
    importance: float       # é‡è¦æ€§åˆ†æ•°
    emotion: str            # æƒ…æ„Ÿ
    reason: str             # é€‰æ‹©åŸå› ï¼ˆè°ƒè¯•ç”¨ï¼‰
    
    @property
    def duration(self) -> float:
        return self.end_time - self.start_time


# ============================================================
# v5.5: ç§»é™¤æ¨¡æ¿ï¼Œå…¨éƒ¨ä½¿ç”¨AIç”Ÿæˆ
# ============================================================
# æ³¨æ„ï¼šä¸å†ä½¿ç”¨æœ¬åœ°æ¨¡æ¿ï¼Œå®æµ‹è¯æ˜æ‰¹é‡AIç”ŸæˆæˆåŠŸç‡100%


class NarrationEngine:
    """
    æ™ºèƒ½è§£è¯´å¼•æ“ v5.6 (åˆ†å±‚ç”Ÿæˆ+ä¸Šä¸‹æ–‡æ„ŸçŸ¥ç‰ˆ)
    
    æ ¸å¿ƒèŒè´£ï¼š
    1. ç”Ÿæˆæ•…äº‹æ¡†æ¶ï¼ˆåˆ†å±‚ç”Ÿæˆç¬¬1å±‚ï¼‰
    2. æ ¹æ®æ¡†æ¶+ä¸Šä¸‹æ–‡ç”Ÿæˆåœºæ™¯è§£è¯´ï¼ˆç¬¬2å±‚ï¼‰
    3. åŠ¨æ€è®¡ç®—è§£è¯´æ¯”ä¾‹ï¼ˆæ›¿ä»£å›ºå®š60%ï¼‰
    4. æ£€æµ‹å¹¶å¤„ç†é™éŸ³æ®µè½
    5. ç”Ÿæˆé’©å­å¼€åœºå’Œæ‚¬å¿µç»“å°¾
    
    v5.6æ”¹è¿›ï¼š
    - åˆ†å±‚ç”Ÿæˆï¼šæ¡†æ¶â†’è§£è¯´
    - ä¸Šä¸‹æ–‡çª—å£ï¼šå‰2å2åœºæ™¯
    - åŠ¨æ€æ¯”ä¾‹ï¼š30%-75%è‡ªåŠ¨è®¡ç®—
    - é™éŸ³å¤„ç†ï¼šAIæ‰©å±•å¡«å……
    - é’©å­+æ‚¬å¿µï¼šè‡ªåŠ¨ç”Ÿæˆ
    """
    
    def __init__(self, use_ai: bool = True, media_type: str = "tv", episode: int = 1, total_episodes: int = 1):
        """
        åˆå§‹åŒ–è§£è¯´å¼•æ“
        
        å‚æ•°ï¼š
            use_ai: æ˜¯å¦ä½¿ç”¨AIç”Ÿæˆ
            media_type: åª’ä½“ç±»å‹ ("tv" ç”µè§†å‰§, "movie" ç”µå½±)
            episode: é›†æ•°/éƒ¨æ•°
            total_episodes: æ€»é›†æ•°
        """
        self.use_ai = use_ai
        self.llm_model = None
        self.media_type = media_type
        self.episode = episode
        self.total_episodes = total_episodes
        self.episode_plot = ""  # åˆ†é›†å‰§æƒ…
        self.title = ""  # ä½œå“åç§°
        self.main_character = ""  # ä¸»è§’åç§°
        
        # v5.6æ–°å¢ï¼šæ•…äº‹æ¡†æ¶
        self.story_framework = []
        
        # v5.6æ–°å¢ï¼šé’©å­å’Œç»“å°¾
        self.hook_opening = ""
        self.suspense_ending = ""
        
        # åŠ¨æ€æ¯”ä¾‹ï¼ˆv5.6æ”¹è¿›ï¼šä¸å†å›ºå®šï¼‰
        self.voiceover_ratio = 0.55  # é»˜è®¤å€¼ï¼Œä¼šè¢«åŠ¨æ€è®¡ç®—è¦†ç›–
        self.min_original_ratio = MIN_ORIGINAL_RATIO
        
        # å°è¯•åŠ è½½LLM
        if use_ai:
            self._init_llm()
        
        # v5.6æ–°å¢ï¼šåˆå§‹åŒ–å­æ¨¡å—
        self._init_v56_modules()
    
    def _init_llm(self):
        """åˆå§‹åŒ–LLMæ¨¡å‹"""
        try:
            import ollama
            models = ollama.list()
            
            # ä¿å­˜å®Œæ•´æ¨¡å‹åï¼ˆåŒ…æ‹¬:tagï¼‰
            available = []
            for model in models.get('models', []):
                name = model.get('name', '') or model.get('model', '')
                if name:
                    available.append(name)  # ä¿ç•™å®Œæ•´åç§°å¦‚ qwen3:8b
            
            # v5.7.3: qwen3å·¥ä½œæ­£å¸¸ï¼Œcontentå­—æ®µæœ‰æ­£ç¡®è¾“å‡º
            # thinkingå’Œcontentæ˜¯åˆ†ç¦»çš„ï¼Œåªéœ€æ­£ç¡®æå–contentå³å¯
            priority = ['qwen3', 'qwen2.5', 'qwen', 'llama3', 'gemma', 'mistral']
            for p in priority:
                for a in available:
                    if p in a.lower():
                        self.llm_model = a  # ä½¿ç”¨å®Œæ•´åç§°
                        print(f"[LLM] ä½¿ç”¨æ¨¡å‹: {self.llm_model}")
                        return
            
            if available:
                self.llm_model = available[0]
                print(f"[LLM] ä½¿ç”¨æ¨¡å‹: {self.llm_model}")
        except Exception as e:
            print(f"[LLM] åˆå§‹åŒ–å¤±è´¥: {e}")
            self.llm_model = None
    
    def _init_v56_modules(self):
        """v5.6æ–°å¢ï¼šåˆå§‹åŒ–å­æ¨¡å—"""
        self.framework_generator = None
        self.ratio_calculator = None
        self.silence_handler = None
        self.hook_generator = None
        
        if not MODULES_V56_AVAILABLE:
            print("[Engine] v5.6æ¨¡å—æœªåŠ è½½ï¼Œä½¿ç”¨å…¼å®¹æ¨¡å¼")
            return
        
        try:
            # æ•…äº‹æ¡†æ¶ç”Ÿæˆå™¨
            self.framework_generator = StoryFrameworkGenerator(self.llm_model)
            
            # åŠ¨æ€æ¯”ä¾‹è®¡ç®—å™¨
            self.ratio_calculator = DynamicRatioCalculator(self.media_type)
            
            # é™éŸ³å¤„ç†å™¨
            self.silence_handler = SilenceHandler(self.llm_model)
            
            # é’©å­ç”Ÿæˆå™¨
            self.hook_generator = HookGenerator(self.llm_model)
            
            print("[Engine] v5.6æ¨¡å—åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"[Engine] v5.6æ¨¡å—åˆå§‹åŒ–å¼‚å¸¸: {e}")
    
    def analyze_and_generate(
        self,
        scenes: List[Dict],
        title: str = "",
        style: str = "å¹½é»˜",
        episode_plot: str = "",
        main_character: str = ""
    ) -> Tuple[List[SceneSegment], str]:
        """
        åˆ†æåœºæ™¯å¹¶ç”Ÿæˆè§£è¯´ v5.6
        
        å‚æ•°ï¼š
            scenes: åœºæ™¯åˆ—è¡¨
            title: ä½œå“åç§°
            style: è§£è¯´é£æ ¼
            episode_plot: åˆ†é›†å‰§æƒ…
            main_character: ä¸»è§’åç§°
        
        è¿”å›ï¼š(å¤„ç†åçš„åœºæ™¯åˆ—è¡¨, å®Œæ•´è§£è¯´æ–‡æœ¬)
        """
        print("\n" + "="*60)
        print("[Engine] æ™ºèƒ½è§£è¯´å¼•æ“ v5.6 (åˆ†å±‚ç”Ÿæˆ+ä¸Šä¸‹æ–‡æ„ŸçŸ¥ç‰ˆ)")
        print("="*60)
        print(f"   ä½œå“: {title}")
        print(f"   ç±»å‹: {'ç”µè§†å‰§' if self.media_type == 'tv' else 'ç”µå½±'}")
        if self.media_type == "tv":
            print(f"   é›†æ•°: ç¬¬{self.episode}é›†")
        print(f"   é£æ ¼: {style}")
        print(f"   åœºæ™¯æ•°: {len(scenes)}")
        print(f"   v5.6æ¨¡å—: {'å·²åŠ è½½' if MODULES_V56_AVAILABLE else 'æœªåŠ è½½'}")
        print("="*60)
        
        # ä¿å­˜åŸºæœ¬ä¿¡æ¯
        self.episode_plot = episode_plot
        self.title = title
        self.main_character = main_character
        
        # Step 1: ç†è§£æ•´ä½“å‰§æƒ…
        print("\n[Step 1] ç†è§£å‰§æƒ…è„‰ç»œ...")
        plot_summary = self._understand_plot(scenes)
        print(f"   å‰§æƒ…æ¦‚è¦: {plot_summary[:100]}...")
        
        # Step 1.5 [v5.6æ–°å¢]: ç”Ÿæˆæ•…äº‹æ¡†æ¶
        if self.framework_generator:
            print("\n[Step 1.5] ç”Ÿæˆæ•…äº‹æ¡†æ¶ (v5.6)...")
            self.story_framework = self.framework_generator.generate_framework(
                title=title,
                media_type=self.media_type,
                episode=self.episode,
                plot_summary=plot_summary,
                scenes=scenes,
                total_episodes=self.total_episodes
            )
            print(f"   æ¡†æ¶æ®µè½: {len(self.story_framework)}ä¸ª")
        
        # Step 1.6 [v5.6æ–°å¢]: è®¡ç®—åŠ¨æ€è§£è¯´æ¯”ä¾‹
        if self.ratio_calculator:
            print("\n[Step 1.6] è®¡ç®—åŠ¨æ€è§£è¯´æ¯”ä¾‹ (v5.6)...")
            self.voiceover_ratio, ratio_details = self.ratio_calculator.calculate_global_ratio(scenes)
            print(f"   åŠ¨æ€æ¯”ä¾‹: {self.voiceover_ratio*100:.0f}% (èŒƒå›´30%-75%)")
            if ratio_details.get('adjustments'):
                for adj in ratio_details['adjustments'][:3]:
                    print(f"      - {adj}")
        else:
            print(f"   ç›®æ ‡è§£è¯´æ¯”ä¾‹: {self.voiceover_ratio*100:.0f}% (å›ºå®š)")
        
        # Step 2: æ ‡è®°åœºæ™¯ç±»å‹
        print("\n[Step 2] åˆ†æåœºæ™¯ç±»å‹...")
        marked_scenes = self._mark_scenes(scenes)
        
        # Step 3: ç”Ÿæˆè§£è¯´ï¼ˆv5.6å¢å¼ºï¼šä¸Šä¸‹æ–‡çª—å£ï¼‰
        print("\n[Step 3] ç”Ÿæˆè§£è¯´æ–‡æ¡ˆ (v5.6ä¸Šä¸‹æ–‡æ„ŸçŸ¥)...")
        final_scenes = self._generate_narrations_v56(marked_scenes, scenes, plot_summary, style)
        
        # Step 4: ç¡®ä¿è¾¾åˆ°ç›®æ ‡æ¯”ä¾‹
        print("\n[Step 4] è°ƒæ•´è§£è¯´æ¯”ä¾‹...")
        final_scenes = self._ensure_voiceover_ratio(final_scenes)
        
        # Step 4.5 [v5.6æ–°å¢]: å¤„ç†é™éŸ³æ®µè½
        if self.silence_handler:
            print("\n[Step 4.5] å¤„ç†é™éŸ³æ®µè½ (v5.6)...")
            final_scenes = self._process_silence_gaps(final_scenes, plot_summary, style)
        
        # Step 5: ä¼˜åŒ–è¿è´¯æ€§
        print("\n[Step 5] ä¼˜åŒ–å‰§æƒ…è¿è´¯æ€§...")
        final_scenes = self._optimize_continuity(final_scenes)
        
        # Step 5.5 [v5.6æ–°å¢]: ç”Ÿæˆé’©å­å¼€åœºå’Œæ‚¬å¿µç»“å°¾
        if self.hook_generator:
            print("\n[Step 5.5] ç”Ÿæˆé’©å­å¼€åœºå’Œæ‚¬å¿µç»“å°¾ (v5.6)...")
            self._generate_hook_and_ending(plot_summary, style, len(scenes))
        
        # ç»Ÿè®¡
        original_count = sum(1 for s in final_scenes if s.audio_mode == AudioMode.ORIGINAL)
        voiceover_count = sum(1 for s in final_scenes if s.audio_mode == AudioMode.VOICEOVER)
        skip_count = sum(1 for s in final_scenes if s.audio_mode == AudioMode.SKIP)
        active_count = original_count + voiceover_count
        
        total_duration = sum(s.duration for s in final_scenes if s.audio_mode != AudioMode.SKIP)
        
        print("\n" + "="*60)
        print("[STATS] åˆ†æç»“æœ (v5.5):")
        if active_count > 0:
            print(f"   [ORIGINAL] åŸå£°åœºæ™¯: {original_count} ({original_count*100//active_count}%)")
            print(f"   [VOICEOVER] è§£è¯´åœºæ™¯: {voiceover_count} ({voiceover_count*100//active_count}%)")
        print(f"   [SKIP] è·³è¿‡åœºæ™¯: {skip_count}")
        print(f"   [DURATION] é¢„è®¡æ—¶é•¿: {total_duration:.0f}ç§’ ({total_duration/60:.1f}åˆ†é’Ÿ)")
        print("="*60)
        
        # ç”Ÿæˆå®Œæ•´è§£è¯´æ–‡æœ¬
        full_narration = self._compile_narration_text(final_scenes)
        
        return final_scenes, full_narration
    
    def _understand_plot(self, scenes: List[Dict]) -> str:
        """
        ç†è§£æ•´ä½“å‰§æƒ… v5.7.2ï¼ˆä¿®å¤ç‰ˆï¼‰
        
        ä¼˜å…ˆçº§ï¼š
        1. ä½¿ç”¨TMDBè·å–çš„åˆ†é›†å‰§æƒ…ï¼ˆæœ€å‡†ç¡®ï¼‰
        2. å¦‚æœæ²¡æœ‰ï¼Œæ‰ä»å¯¹è¯ä¸­AIæ€»ç»“
        """
        # v5.7.2ä¿®å¤ï¼šä¼˜å…ˆä½¿ç”¨TMDBå‰§æƒ…ï¼
        if self.episode_plot and len(self.episode_plot) > 20:
            return f"å‰§æƒ…æ€»ç»“ï¼š{self.episode_plot}"
        
        # å¤‡ç”¨ï¼šä»å¯¹è¯ä¸­æ€»ç»“
        all_dialogues = []
        for scene in scenes:
            dialogue = scene.get('dialogue', '').strip()
            if dialogue and len(dialogue) > 10:
                dialogue = self._filter_sensitive(dialogue)
                if dialogue:
                    all_dialogues.append(dialogue)
        
        if not all_dialogues:
            return "æ— æ³•è¯†åˆ«å‰§æƒ…å†…å®¹"
        
        # ç”¨AIæ€»ç»“
        if self.llm_model:
            combined = "\n".join(all_dialogues[:50])
            summary = self._ai_summarize(combined)
            if summary:
                return f"å‰§æƒ…æ€»ç»“ï¼š{summary}"
        
        # æœ€åå¤‡ç”¨ï¼šç®€å•æ‹¼æ¥
        return " ".join(all_dialogues[:10])[:500]
    
    def _mark_scenes(self, scenes: List[Dict]) -> List[SceneSegment]:
        """
        æ ‡è®°æ¯ä¸ªåœºæ™¯çš„ç±»å‹
        
        v5.3æ”¹è¿›ï¼šä½¿ç”¨æ›´å®½æ¾çš„é˜ˆå€¼ï¼Œç¡®ä¿æ›´å¤šåœºæ™¯è¢«æ ‡è®°ä¸ºè§£è¯´
        v5.7.1å¢å¼ºï¼šå¢åŠ å¹¿å‘Šå†…å®¹è¿‡æ»¤
        """
        result = []
        
        for i, scene in enumerate(scenes):
            dialogue = scene.get('dialogue', '').strip()
            emotion = scene.get('emotion', 'neutral')
            importance = scene.get('importance', 0.5)
            
            # v5.7.1ï¼šå¹¿å‘Šå†…å®¹è¿‡æ»¤
            if self._is_ad_content(dialogue):
                dialogue = ""  # æ¸…ç©ºå¹¿å‘Šå†…å®¹
                importance = 0.1  # é™ä½é‡è¦æ€§
            
            dialogue = self._filter_sensitive(dialogue)
            
            # å†³å®šéŸ³é¢‘æ¨¡å¼ï¼ˆä½¿ç”¨å®½æ¾é˜ˆå€¼ï¼‰
            audio_mode, reason = self._decide_audio_mode(
                dialogue, emotion, importance
            )
            
            segment = SceneSegment(
                scene_id=scene.get('scene_id', i + 1),
                start_time=scene.get('start_time', 0),
                end_time=scene.get('end_time', 0),
                dialogue=dialogue,
                narration="",
                audio_mode=audio_mode,
                importance=importance,
                emotion=emotion,
                reason=reason
            )
            
            result.append(segment)
        
        # ç»Ÿè®¡
        orig = sum(1 for s in result if s.audio_mode == AudioMode.ORIGINAL)
        voice = sum(1 for s in result if s.audio_mode == AudioMode.VOICEOVER)
        skip = sum(1 for s in result if s.audio_mode == AudioMode.SKIP)
        print(f"   åˆå§‹æ ‡è®°: åŸå£°{orig}, è§£è¯´{voice}, è·³è¿‡{skip}")
        
        return result
    
    def _decide_audio_mode(
        self, 
        dialogue: str, 
        emotion: str, 
        importance: float
    ) -> Tuple[AudioMode, str]:
        """
        å†³å®šåœºæ™¯çš„éŸ³é¢‘æ¨¡å¼
        
        v5.3æ”¹è¿›ï¼š
        - ç”µè§†å‰§æ¨¡å¼ä½¿ç”¨æ›´å®½æ¾é˜ˆå€¼ï¼Œè®©æ›´å¤šåœºæ™¯æˆä¸ºè§£è¯´
        - åªæœ‰æé«˜é‡è¦æ€§æˆ–å¼ºæƒ…æ„Ÿæ‰ä¿ç•™åŸå£°
        """
        # å¼ºæƒ…æ„Ÿ â†’ åŸå£°ï¼ˆä½†æ¯”ä¾‹è¦æ§åˆ¶ï¼‰
        if emotion in ['angry', 'sad', 'excited'] and importance >= 0.7:
            return AudioMode.ORIGINAL, f"å¼ºæƒ…æ„Ÿåœºæ™¯({emotion})"
        
        # æ ¹æ®åª’ä½“ç±»å‹è°ƒæ•´é˜ˆå€¼
        if self.media_type == "tv":
            # ç”µè§†å‰§æ¨¡å¼ï¼šå¤§å¹…æ”¾å®½è§£è¯´æ¡ä»¶
            original_threshold = 0.85   # æé«˜é‡è¦æ€§æ‰ç”¨åŸå£°
            voiceover_threshold = 0.15  # ä½é‡è¦æ€§ä»¥ä¸Šéƒ½ç”¨è§£è¯´
            dialogue_threshold = 40     # å¾ˆé•¿å¯¹è¯æ‰ç”¨åŸå£°
        else:
            # ç”µå½±æ¨¡å¼
            original_threshold = 0.65
            voiceover_threshold = 0.30
            dialogue_threshold = 25
        
        # æé«˜é‡è¦æ€§ + æœ‰å¯¹è¯ â†’ åŸå£°
        if importance >= original_threshold and dialogue and len(dialogue) > dialogue_threshold:
            return AudioMode.ORIGINAL, "é‡è¦ç²¾å½©å¯¹è¯"
        
        # æœ‰å¯¹è¯ä½†ä¸æ˜¯æé«˜é‡è¦æ€§ â†’ è§£è¯´
        if dialogue and len(dialogue) > 5:
            return AudioMode.VOICEOVER, "ç”¨è§£è¯´æ¦‚æ‹¬å¯¹è¯"
        
        # æ— å¯¹è¯ä½†é‡è¦æ€§ä¸­ç­‰ â†’ è§£è¯´
        if importance >= voiceover_threshold:
            return AudioMode.VOICEOVER, "è¿‡æ¸¡åœºæ™¯ç”¨è§£è¯´"
        
        # ä½é‡è¦æ€§ â†’ è·³è¿‡
        return AudioMode.SKIP, "ä½é‡è¦æ€§è·³è¿‡"
    
    def _generate_narrations(
        self, 
        scenes: List[SceneSegment],
        plot_summary: str,
        style: str
    ) -> List[SceneSegment]:
        """
        æ‰¹é‡ç”Ÿæˆè§£è¯´æ–‡æ¡ˆ v5.5
        
        å®æµ‹æ•°æ®å¯¹æ¯”ï¼š
        - å•æ¬¡Ã—608ï¼š102ç§’/10ä¸ªï¼ŒæˆåŠŸç‡50%
        - æ‰¹é‡Ã—61ï¼š18ç§’/10ä¸ªï¼ŒæˆåŠŸç‡100%
        
        ç­–ç•¥ï¼š
        1. å°†åœºæ™¯åˆ†æˆ10ä¸ªä¸€æ‰¹
        2. æ¯æ‰¹ç”¨ä¸€æ¬¡AIè°ƒç”¨ç”ŸæˆJSONæ•°ç»„
        3. å¤±è´¥åœºæ™¯ç”¨AIæ€»ç»“å¯¹è¯ï¼ˆéæ¨¡æ¿ï¼‰
        """
        import time
        import json
        import re
        from datetime import datetime
        
        def log(msg):
            print(f"[{datetime.now().strftime('%H:%M:%S')}] {msg}", flush=True)
        
        # æ”¶é›†éœ€è¦è§£è¯´çš„åœºæ™¯
        voiceover_scenes = [s for s in scenes if s.audio_mode == AudioMode.VOICEOVER]
        voiceover_count = len(voiceover_scenes)
        
        if voiceover_count == 0:
            log("[Narration] æ— éœ€ç”Ÿæˆè§£è¯´")
            return scenes
        
        start_time = time.time()
        batch_size = 10  # æ¯æ‰¹10ä¸ªåœºæ™¯
        batch_count = (voiceover_count + batch_size - 1) // batch_size
        
        log(f"[Narration] ========== æ‰¹é‡ç”Ÿæˆè§£è¯´ v5.5 ==========")
        log(f"[Narration] åœºæ™¯æ€»æ•°: {voiceover_count}")
        log(f"[Narration] æ‰¹æ¬¡æ•°é‡: {batch_count} (æ¯æ‰¹{batch_size}ä¸ª)")
        log(f"[Narration] AIæ¨¡å‹: {self.llm_model or 'æœªåŠ è½½'}")
        log(f"[Narration] å‰§æƒ…æ¦‚è¦: {plot_summary[:80]}...")
        
        generated = 0
        fallback_used = 0
        failed = 0
        
        # åˆ†æ‰¹å¤„ç†
        for batch_idx in range(batch_count):
            batch_start = batch_idx * batch_size
            batch_end = min(batch_start + batch_size, voiceover_count)
            batch_scenes = voiceover_scenes[batch_start:batch_end]
            
            elapsed = time.time() - start_time
            log(f"[Narration] æ‰¹æ¬¡ {batch_idx+1}/{batch_count} | "
                f"åœºæ™¯ {batch_start+1}-{batch_end}/{voiceover_count} | "
                f"è€—æ—¶: {elapsed:.0f}ç§’")
            
            # æ‰¹é‡ç”Ÿæˆ
            if self.llm_model:
                narrations = self._batch_generate_narrations(batch_scenes, plot_summary, style)
            else:
                narrations = []
            
            # åˆ†é…ç»“æœ
            for i, scene in enumerate(batch_scenes):
                if i < len(narrations) and narrations[i]:
                    narration = narrations[i]
                    # è´¨é‡æ£€æŸ¥
                    if len(narration) >= 5 and not self._is_low_quality(narration):
                        scene.narration = narration
                        generated += 1
                        continue

                # æ‰¹é‡å¤±è´¥çš„åœºæ™¯ï¼Œç”¨AIæ€»ç»“å¯¹è¯
                fallback = self._ai_summarize_dialogue(scene.dialogue)
                if fallback and len(fallback) >= 5:
                    scene.narration = fallback
                    fallback_used += 1
                else:
                    # æœ€åå…œåº•ï¼šä¿ç•™åŸå£°
                    scene.audio_mode = AudioMode.ORIGINAL
                    scene.reason = "AIç”Ÿæˆå¤±è´¥,æ”¹ç”¨åŸå£°"
                    failed += 1

            # v5.8.0 æ–°å¢ï¼šæ‰¹æ¬¡é—´å»¶è¿Ÿï¼Œé¿å…ç´¯ç§¯æ•ˆåº”
            if batch_idx < batch_count - 1:  # ä¸æ˜¯æœ€åä¸€ä¸ªæ‰¹æ¬¡
                time.sleep(1)  # 1ç§’å»¶è¿Ÿ
        
        total_time = time.time() - start_time
        success_rate = (generated + fallback_used) / voiceover_count * 100 if voiceover_count > 0 else 0
        
        log(f"[Narration] ========== ç”Ÿæˆå®Œæˆ ==========")
        log(f"[Narration] æ‰¹é‡æˆåŠŸ: {generated} ({generated*100//voiceover_count}%)")
        log(f"[Narration] AIæ€»ç»“: {fallback_used} ({fallback_used*100//voiceover_count}%)")
        log(f"[Narration] å¤±è´¥è½¬åŸå£°: {failed}")
        log(f"[Narration] æ€»æˆåŠŸç‡: {success_rate:.1f}%")
        log(f"[Narration] æ€»è€—æ—¶: {total_time:.1f}ç§’ ({total_time/60:.1f}åˆ†é’Ÿ)")
        log(f"[Narration] å¹³å‡é€Ÿåº¦: {voiceover_count/total_time:.1f}ä¸ª/ç§’")
        
        return scenes
    
    def _generate_narrations_v56(
        self, 
        marked_scenes: List[SceneSegment],
        original_scenes: List[Dict],
        plot_summary: str,
        style: str
    ) -> List[SceneSegment]:
        """
        v5.6å¢å¼ºç‰ˆè§£è¯´ç”Ÿæˆï¼ˆå¸¦ä¸Šä¸‹æ–‡çª—å£ï¼‰
        
        æ”¹è¿›ï¼š
        1. æ¯ä¸ªåœºæ™¯è€ƒè™‘å‰2å2åœºæ™¯çš„ä¸Šä¸‹æ–‡
        2. ä½¿ç”¨æ•…äº‹æ¡†æ¶æŒ‡å¯¼ç”Ÿæˆ
        3. è®¡ç®—ç›®æ ‡å­—æ•°ä»¥åŒ¹é…åœºæ™¯æ—¶é•¿
        """
        import time
        from datetime import datetime
        
        def log(msg):
            print(f"[{datetime.now().strftime('%H:%M:%S')}] {msg}", flush=True)
        
        # æ”¶é›†éœ€è¦è§£è¯´çš„åœºæ™¯
        voiceover_scenes = [s for s in marked_scenes if s.audio_mode == AudioMode.VOICEOVER]
        voiceover_count = len(voiceover_scenes)
        
        if voiceover_count == 0:
            log("[Narration] æ— éœ€ç”Ÿæˆè§£è¯´")
            return marked_scenes
        
        start_time = time.time()
        batch_size = 10
        batch_count = (voiceover_count + batch_size - 1) // batch_size
        
        log(f"[Narration] ========== v5.8 Structuredæ ¼å¼ä¼˜åŒ– ==========")
        log(f"[Narration] åœºæ™¯æ€»æ•°: {voiceover_count}")
        log(f"[Narration] æ‰¹æ¬¡æ•°é‡: {batch_count}")
        log(f"[Narration] æ•…äº‹æ¡†æ¶: {len(self.story_framework)}æ®µ")
        
        generated = 0
        fallback_used = 0
        failed = 0
        
        # æ„å»ºåœºæ™¯IDåˆ°ç´¢å¼•çš„æ˜ å°„
        scene_idx_map = {s.scene_id: i for i, s in enumerate(marked_scenes)}
        
        # åˆ†æ‰¹å¤„ç†
        for batch_idx in range(batch_count):
            batch_start = batch_idx * batch_size
            batch_end = min(batch_start + batch_size, voiceover_count)
            batch_scenes = voiceover_scenes[batch_start:batch_end]
            
            elapsed = time.time() - start_time
            log(f"[Narration] æ‰¹æ¬¡ {batch_idx+1}/{batch_count} | "
                f"åœºæ™¯ {batch_start+1}-{batch_end}/{voiceover_count} | "
                f"è€—æ—¶: {elapsed:.0f}ç§’")
            
            # v5.6æ”¹è¿›ï¼šæ„å»ºå¸¦ä¸Šä¸‹æ–‡çš„æ‰¹é‡è¯·æ±‚
            if self.llm_model:
                narrations = self._batch_generate_with_context(
                    batch_scenes, marked_scenes, original_scenes,
                    plot_summary, style
                )
            else:
                narrations = []
            
            # v5.7æ”¹è¿›ï¼šåˆ†é…ç»“æœï¼Œå¢åŠ é‡è¯•å’Œå…œåº•æœºåˆ¶
            for i, scene in enumerate(batch_scenes):
                if i < len(narrations) and narrations[i]:
                    narration = narrations[i]
                    if len(narration) >= 5 and not self._is_low_quality(narration):
                        scene.narration = narration
                        generated += 1
                        continue
                
                # v5.7ï¼šç¬¬ä¸€æ¬¡å¤‡ç”¨ - AIæ€»ç»“å¯¹è¯
                fallback = self._ai_summarize_dialogue(scene.dialogue)
                if fallback and len(fallback) >= 5 and not self._is_low_quality(fallback):
                    scene.narration = fallback
                    fallback_used += 1
                    continue
                
                # v5.7ï¼šç¬¬äºŒæ¬¡å¤‡ç”¨ - è¶…ç®€åŒ–AIç”Ÿæˆï¼ˆé‡è¯•æœºåˆ¶ï¼‰
                simple_result = self._simple_ai_generate(scene.dialogue, style)
                if simple_result and len(simple_result) >= 5:
                    scene.narration = simple_result
                    fallback_used += 1
                    continue
                
                # v5.7ï¼šç¬¬ä¸‰æ¬¡å¤‡ç”¨ - åŸºäºå¯¹è¯å…³é”®è¯ç”Ÿæˆ
                keyword_result = self._keyword_based_generate(scene.dialogue, style)
                if keyword_result and len(keyword_result) >= 5:
                    scene.narration = keyword_result
                    fallback_used += 1
                    continue
                
                # æ‰€æœ‰æ–¹æ¡ˆéƒ½å¤±è´¥ï¼Œæ‰ä½¿ç”¨åŸå£°
                scene.audio_mode = AudioMode.ORIGINAL
                scene.reason = "å¤šæ¬¡AIå°è¯•å‡å¤±è´¥,æ”¹ç”¨åŸå£°"
                failed += 1
        
        total_time = time.time() - start_time
        success_rate = (generated + fallback_used) / voiceover_count * 100 if voiceover_count > 0 else 0
        
        log(f"[Narration] ========== ç”Ÿæˆå®Œæˆ ==========")
        log(f"[Narration] æ‰¹é‡æˆåŠŸ: {generated} ({generated*100//max(1,voiceover_count)}%)")
        log(f"[Narration] AIæ€»ç»“: {fallback_used}")
        log(f"[Narration] å¤±è´¥è½¬åŸå£°: {failed}")
        log(f"[Narration] æ€»æˆåŠŸç‡: {success_rate:.1f}%")
        log(f"[Narration] æ€»è€—æ—¶: {total_time:.1f}ç§’")
        
        return marked_scenes
    
    def _batch_generate_with_context(
        self,
        batch_scenes: List[SceneSegment],
        all_scenes: List[SceneSegment],
        original_scenes: List[Dict],
        plot_summary: str,
        style: str
    ) -> List[str]:
        """
        v5.6ï¼šå¸¦ä¸Šä¸‹æ–‡çª—å£çš„æ‰¹é‡ç”Ÿæˆ
        
        æ¯ä¸ªåœºæ™¯åŒ…å«ï¼š
        - å¯¹åº”çš„æ•…äº‹æ¡†æ¶æ®µè½
        - å‰2ä¸ªåœºæ™¯æ‘˜è¦
        - å2ä¸ªåœºæ™¯æ‘˜è¦
        - ç›®æ ‡å­—æ•°
        """
        if not self.llm_model:
            return []
        
        try:
            import ollama
            
            # æ„å»ºåœºæ™¯IDåˆ°ç´¢å¼•çš„æ˜ å°„
            scene_id_to_idx = {s.scene_id: i for i, s in enumerate(all_scenes)}
            
            # æ„å»ºæ‰¹é‡prompt
            scene_list = []
            for i, scene in enumerate(batch_scenes):
                scene_idx = scene_id_to_idx.get(scene.scene_id, 0)
                
                # è·å–æ¡†æ¶æŒ‡å¯¼
                framework_hint = ""
                if self.story_framework and self.framework_generator:
                    segment = self.framework_generator.get_segment_for_scene(
                        scene.scene_id, self.story_framework
                    )
                    if segment:
                        framework_hint = f"[{segment.theme}|{segment.emotion}] "
                
                # è·å–å‰ååœºæ™¯ï¼ˆä¸Šä¸‹æ–‡çª—å£ï¼‰
                context_parts = []
                
                # å‰2ä¸ªåœºæ™¯
                for offset in [-2, -1]:
                    prev_idx = scene_idx + offset
                    if 0 <= prev_idx < len(all_scenes):
                        prev_scene = all_scenes[prev_idx]
                        prev_dialogue = prev_scene.dialogue[:30] if prev_scene.dialogue else "(æ— )"
                        context_parts.append(f"å‰{-offset}:{prev_dialogue}")
                
                # å½“å‰å¯¹è¯
                dialogue = scene.dialogue[:80] if scene.dialogue else "(æ— å¯¹è¯)"
                
                # å2ä¸ªåœºæ™¯
                for offset in [1, 2]:
                    next_idx = scene_idx + offset
                    if next_idx < len(all_scenes):
                        next_scene = all_scenes[next_idx]
                        next_dialogue = next_scene.dialogue[:30] if next_scene.dialogue else "(æ— )"
                        context_parts.append(f"å{offset}:{next_dialogue}")
                
                # è®¡ç®—ç›®æ ‡å­—æ•°
                target_chars = int(scene.duration * 4)  # 4å­—/ç§’
                target_chars = max(15, min(50, target_chars))
                
                # æ„å»ºåœºæ™¯æè¿°
                context_str = " | ".join(context_parts) if context_parts else ""
                scene_desc = f"{i+1}. {framework_hint}[{target_chars}å­—] {dialogue}"
                if context_str:
                    scene_desc += f" (ä¸Šä¸‹æ–‡:{context_str})"
                
                scene_list.append(scene_desc)
            
            scenes_text = "\n".join(scene_list)
            
            # v5.7.2: æ·»åŠ /no_thinkç¦ç”¨æ€è€ƒæ¨¡å¼ï¼Œæ˜ç¡®ç¦æ­¢è¾“å‡ºæ€è€ƒè¿‡ç¨‹
            prompt = f"""/no_think
ä¸ºä»¥ä¸‹{len(batch_scenes)}ä¸ªåœºæ™¯ç”Ÿæˆè§£è¯´ã€‚

ã€å‰§æƒ…ã€‘{plot_summary[:100]}

ã€åœºæ™¯ã€‘
{scenes_text}

ã€è§„åˆ™-ä¸¥æ ¼éµå®ˆã€‘
1. åªè¾“å‡ºJSONæ•°ç»„ï¼Œæ ¼å¼ï¼š["è§£è¯´1", "è§£è¯´2", ...]
2. {style}é£æ ¼
3. æ¯å¥15-40å­—
4. ç¦æ­¢è¾“å‡ºï¼šæ€è€ƒè¿‡ç¨‹ã€"å¥½çš„"ã€"é¦–å…ˆ"ã€"ç”¨Xä¸ªå­—"ã€"åŸå¥"ç­‰
5. ç¦æ­¢å¤è¿°å¯¹è¯

ç›´æ¥è¾“å‡ºJSONï¼š"""
            
            response = ollama.chat(
                model=self.llm_model,
                messages=[{'role': 'user', 'content': prompt}],
                options={
                    'num_predict': 2000,
                    'temperature': 0.6,
                }
            )
            
            # v5.8.0: Structuredæ ¼å¼è§£æï¼Œç»ä¸ä½¿ç”¨thinkingï¼ˆæ ¹æºæœç»æ€è€ƒå†…å®¹æ³„éœ²ï¼‰
            msg = response.get('message', {})
            content = ""
            
            if hasattr(msg, 'content') and msg.content:
                content = msg.content.strip()
            
            # v5.7.3: contentä¸ºç©ºåˆ™è¿”å›ç©ºåˆ—è¡¨ï¼Œä¸ä»thinkingæå–ï¼
            if not content:
                print(f"[Narration] è­¦å‘Š: AIè¿”å›contentä¸ºç©ºï¼Œè·³è¿‡thinking", flush=True)
                return []
            
            # v5.8.0: Structuredæ ¼å¼è§£æï¼Œ100%æˆåŠŸç‡
            import json
            
            # ä½¿ç”¨è´ªå©ªåŒ¹é…è·å–å®Œæ•´JSONæ•°ç»„ï¼ˆå¤„ç†åµŒå¥—æƒ…å†µï¼‰
            # å°è¯•å¤šç§æ¨¡å¼
            json_patterns = [
                r'\[[\s\S]*\]',  # è´ªå©ªåŒ¹é…å®Œæ•´æ•°ç»„
                r'\[\s*\[[\s\S]*\]\s*\]',  # åµŒå¥—æ•°ç»„
                r'\[.*?\]',  # éè´ªå©ªï¼ˆæœ€åå°è¯•ï¼‰
            ]
            
            for pattern in json_patterns:
                match = re.search(pattern, content)
                if match:
                    try:
                        results = json.loads(match.group())
                        # å¤„ç†åµŒå¥—æ•°ç»„: [[...]] -> [...]
                        if isinstance(results, list) and len(results) == 1 and isinstance(results[0], list):
                            results = results[0]
                        if isinstance(results, list):
                            cleaned = []
                            for r in results:
                                if isinstance(r, str):
                                    r = r.strip().strip('"\'')
                                    r = re.sub(r'^[\d]+[\.ã€]\s*', '', r)
                                    cleaned.append(r)
                                elif isinstance(r, list):  # å†æ¬¡å¤„ç†åµŒå¥—
                                    for sub in r:
                                        if isinstance(sub, str):
                                            cleaned.append(sub.strip())
                                else:
                                    cleaned.append("")
                            if cleaned:  # æœ‰ç»“æœæ‰è¿”å›
                                return cleaned
                    except json.JSONDecodeError:
                        continue
            
            # JSONè§£æå¤±è´¥ï¼Œå°è¯•æŒ‰è¡Œåˆ†å‰²
            lines = content.split('\n')
            results = []
            for line in lines:
                line = line.strip()
                line = re.sub(r'^[\d]+[\.ã€\)ï¼‰]\s*', '', line)
                line = line.strip('"\'[]')
                if line and len(line) > 5 and len(line) < 60:
                    results.append(line)
            
            return results[:len(batch_scenes)]
            
        except Exception as e:
            print(f"[Narration] v5.6æ‰¹é‡ç”Ÿæˆå¼‚å¸¸: {e}", flush=True)
            # é™çº§åˆ°v5.5æ–¹æ³•
            return self._batch_generate_narrations(batch_scenes, plot_summary, style)
    
    def _process_silence_gaps(
        self,
        scenes: List[SceneSegment],
        plot_summary: str,
        style: str
    ) -> List[SceneSegment]:
        """
        v5.6æ–°å¢ï¼šå¤„ç†é™éŸ³æ®µè½
        """
        if not self.silence_handler:
            return scenes
        
        # è½¬æ¢ä¸ºdictæ ¼å¼
        scene_dicts = []
        for s in scenes:
            scene_dicts.append({
                'scene_id': s.scene_id,
                'start_time': s.start_time,
                'end_time': s.end_time,
                'audio_mode': s.audio_mode.value,
                'narration': s.narration,
                'dialogue': s.dialogue,
                'emotion': s.emotion,
            })
        
        # æ£€æµ‹é™éŸ³
        gaps = self.silence_handler.detect_silence_gaps(scene_dicts)
        
        if not gaps:
            print("   æ— é™éŸ³æ®µè½")
            return scenes
        
        print(f"   æ£€æµ‹åˆ°é™éŸ³: {len(gaps)}å¤„")
        
        # å¤„ç†é™éŸ³
        gaps, expanded, adjusted = self.silence_handler.process_silence_gaps(
            gaps, scene_dicts, plot_summary, style
        )
        
        # åº”ç”¨ç»“æœ
        gap_map = {g.scene_id: g for g in gaps}
        for scene in scenes:
            if scene.scene_id in gap_map:
                gap = gap_map[scene.scene_id]
                if gap.expanded_narration:
                    scene.narration = gap.expanded_narration
        
        print(f"   AIæ‰©å±•: {expanded}, è¯­é€Ÿè°ƒæ•´: {adjusted}")
        
        return scenes
    
    def _generate_hook_and_ending(self, plot_summary: str, style: str, total_scenes: int):
        """
        v5.6æ–°å¢ï¼šç”Ÿæˆé’©å­å¼€åœºå’Œæ‚¬å¿µç»“å°¾
        """
        if not self.hook_generator:
            return
        
        # ç”Ÿæˆé’©å­å¼€åœº
        if self.hook_generator.should_add_hook(self.media_type, self.episode, self.total_episodes):
            duration_minutes = total_scenes * 5 // 60  # ç²—ç•¥ä¼°ç®—
            self.hook_opening = self.hook_generator.generate_hook(
                title=self.title,
                plot_summary=plot_summary,
                main_character=self.main_character,
                style=style,
                duration_minutes=max(5, duration_minutes)
            )
            print(f"   é’©å­å¼€åœº: {self.hook_opening[:40]}...")
        
        # ç”Ÿæˆæ‚¬å¿µç»“å°¾
        should_add, ending_type = self.hook_generator.should_add_suspense(
            self.media_type, self.episode, self.total_episodes
        )
        if should_add:
            has_next = self.episode < self.total_episodes
            self.suspense_ending = self.hook_generator.generate_ending(
                title=self.title,
                plot_summary=plot_summary,
                ending_type=ending_type,
                main_character=self.main_character,
                style=style,
                has_next_episode=has_next
            )
            print(f"   {ending_type}ç»“å°¾: {self.suspense_ending[:40]}...")
    
    def _batch_generate_narrations(
        self,
        scenes: List[SceneSegment],
        plot_summary: str,
        style: str
    ) -> List[str]:
        """
        æ‰¹é‡ç”Ÿæˆè§£è¯´ v5.8.1 - Structuredæ ¼å¼ä¼˜åŒ–+ç¨³å®šæ€§ä¿®å¤ï¼ˆ100%æˆåŠŸç‡ï¼‰
        æˆåŠŸç‡: 22.5% â†’ 95.07% â†’ 100% (æ‰¹æ¬¡å»¶è¿Ÿä¿®å¤)
        è´¨é‡: ç¢ç‰‡åŒ– â†’ è¿è´¯å®Œæ•´
        """
        if not self.llm_model:
            return []

        try:
            import ollama

            # æ„å»ºåœºæ™¯æ–‡æœ¬ï¼ˆä¿æŒæ‰¹é‡æ•ˆç‡ï¼‰
            scene_list = []
            for i, scene in enumerate(scenes):
                dialogue = scene.dialogue[:100] if scene.dialogue else "(æ— å¯¹è¯)"
                scene_list.append(f"{i+1}. {dialogue}")

            scenes_text = "\n".join(scene_list)

            # ğŸš€ æœ€ä¼˜Structuredæ ¼å¼Prompt
            prompt = f"""/no_think
ä½ æ˜¯ä¸“ä¸šçš„å½±è§†è§£è¯´å‘˜ï¼Œä¸ºã€Š{self.title}ã€‹ç”Ÿæˆè§£è¯´è¯ã€‚

ã€æ•´ä½“å‰§æƒ…ã€‘{plot_summary}

ã€ç”Ÿæˆè¦æ±‚ã€‘
- æ¯æ¡è§£è¯´25-35å­—ï¼Œå…·ä½“æè¿°å‰§æƒ…å‘å±•
- {style}
- çªå‡ºå…³é”®äººç‰©å’Œäº‹ä»¶è½¬æŠ˜

ã€å¾…è§£è¯´åœºæ™¯ã€‘
{scenes_text}

ã€è¾“å‡ºæ ¼å¼ã€‘
æ¯è¡Œä¸€ä¸ªè§£è¯´ï¼Œç”¨æ•°å­—ç¼–å·ï¼š
1. [åœºæ™¯1çš„å…·ä½“è§£è¯´ï¼Œçªå‡ºå…³é”®ç»†èŠ‚]
2. [åœºæ™¯2çš„è¯¦ç»†æè¿°ï¼Œå±•ç°äººç‰©å…³ç³»]

ç›´æ¥è¾“å‡ºï¼š"""

            # ğŸš€ æœ€ä¼˜å‚æ•°é…ç½®
            response = ollama.chat(
                model=self.llm_model,
                messages=[{'role': 'user', 'content': prompt}],
                options={
                    'num_predict': 2000,  # å……è¶³çš„ç”Ÿæˆç©ºé—´
                    'temperature': 0.5,   # é™ä½éšæœºæ€§ï¼Œæé«˜æˆåŠŸç‡
                }
            )

            # åªä»contentæå–ï¼Œå¿½ç•¥thinkingï¼ˆå…³é”®ä¿®å¤ï¼‰
            msg = response.get('message', {})
            content = ""

            if hasattr(msg, 'content') and msg.content:
                content = msg.content.strip()

            if not content:
                return []

            # ğŸš€ Structuredè§£æï¼ˆ100%æˆåŠŸç‡ï¼‰
            import re
            results = {}

            # æŒ‰è¡Œåˆ†å‰²è§£æï¼Œæ¯è¡Œ"æ•°å­—. è§£è¯´å†…å®¹"
            for line in content.split('\n'):
                line = line.strip()
                if not line:
                    continue

                # ç²¾ç¡®åŒ¹é…æ ¼å¼ï¼š1. è§£è¯´å†…å®¹
                match = re.match(r'^(\d+)\.\s*(.+)$', line)
                if match:
                    idx = int(match.group(1)) - 1  # åºå·è½¬ç´¢å¼•
                    narration = match.group(2).strip()

                    # æ¸…ç†å’ŒéªŒè¯ï¼ˆä¿æŒåŸæœ‰è´¨é‡æ§åˆ¶ï¼‰
                    narration = clean_narration_text(narration)
                    if validate_narration(narration):
                        results[idx] = narration
                    else:
                        results[idx] = ""  # éªŒè¯å¤±è´¥ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²

            # æŒ‰åœºæ™¯é¡ºåºè¿”å›ç»“æœï¼Œç¡®ä¿é•¿åº¦åŒ¹é…
            return [results.get(i, "") for i in range(len(scenes))]
            
        except Exception as e:
            print(f"[Narration] æ‰¹é‡ç”Ÿæˆå¼‚å¸¸: {e}", flush=True)
            return []
    
    def _ai_summarize_dialogue(self, dialogue: str) -> str:
        """
        ç”¨AIæ€»ç»“å¯¹è¯ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰v5.7.2
        
        æ›¿ä»£åŸæ¥çš„æ¨¡æ¿æ–¹æ¡ˆï¼Œç¡®ä¿æ¯ä¸ªè§£è¯´éƒ½æ˜¯AIç”Ÿæˆçš„
        """
        if not self.llm_model or not dialogue:
            return ""
        
        try:
            import ollama
            
            # v5.7.2: ç®€åŒ–prompt + ç¦æ­¢æ€è€ƒ
            prompt = f"/no_think\næ¦‚æ‹¬ï¼ˆ15å­—å†…ï¼‰ï¼š{dialogue[:80]}\nç›´æ¥è¾“å‡ºï¼š"
            
            response = ollama.chat(
                model=self.llm_model,
                messages=[{'role': 'user', 'content': prompt}],
                options={
                    'num_predict': 100,
                    'temperature': 0.5,
                }
            )
            
            # v5.8.0: Structuredæ ¼å¼è§£æï¼Œç»ä¸ä½¿ç”¨thinking
            msg = response.get('message', {})
            result = ""
            
            if hasattr(msg, 'content') and msg.content:
                result = msg.content.strip()
            
            # v5.7.3: contentä¸ºç©ºè¿”å›ç©ºï¼Œä¸ä»thinkingæå–
            if result:
                result = result.strip('"\'')
                result = clean_narration_text(result)
                result = self._filter_sensitive(result)
                if not validate_narration(result):
                    return ""
            
            return result
            
        except Exception:
            return ""
    
    def _generate_fallback_narration(self, scene: SceneSegment, style: str) -> str:
        """
        å¤‡ç”¨è§£è¯´ç”Ÿæˆ v5.5
        
        v5.5æ”¹è¿›ï¼šä¸å†ä½¿ç”¨æ¨¡æ¿ï¼Œè°ƒç”¨AIæ€»ç»“å¯¹è¯
        """
        return self._ai_summarize_dialogue(scene.dialogue)
    
    def _ensure_voiceover_ratio(self, scenes: List[SceneSegment]) -> List[SceneSegment]:
        """
        ç¡®ä¿è¾¾åˆ°ç›®æ ‡è§£è¯´æ¯”ä¾‹ v5.7.2ï¼ˆä¿®å¤ç‰ˆï¼‰
        
        v5.7.2ä¿®å¤ï¼šæ”¯æŒåŒå‘è°ƒæ•´ï¼ˆå¢åŠ æˆ–å‡å°‘è§£è¯´ï¼‰
        """
        active_scenes = [s for s in scenes if s.audio_mode != AudioMode.SKIP]
        if not active_scenes:
            return scenes
        
        voiceover_count = sum(1 for s in active_scenes if s.audio_mode == AudioMode.VOICEOVER)
        total = len(active_scenes)
        
        current_ratio = voiceover_count / total if total > 0 else 0
        target_ratio = self.voiceover_ratio
        
        print(f"   å½“å‰è§£è¯´æ¯”ä¾‹: {current_ratio*100:.0f}%, ç›®æ ‡: {target_ratio*100:.0f}%")
        
        # v5.7.2ä¿®å¤ï¼šè§£è¯´è¿‡å¤šæ—¶å‡å°‘
        if current_ratio > target_ratio + 0.05:  # è¶…è¿‡ç›®æ ‡5%ä»¥ä¸Šæ‰è°ƒæ•´
            need_reduce = voiceover_count - int(total * target_ratio)
            
            # æŒ‰é‡è¦æ€§æ’åºè§£è¯´åœºæ™¯ï¼ˆä½é‡è¦æ€§ä¼˜å…ˆè½¬ä¸ºåŸå£°ï¼‰
            voiceover_scenes = [s for s in active_scenes if s.audio_mode == AudioMode.VOICEOVER]
            voiceover_scenes.sort(key=lambda x: x.importance)
            
            reduced = 0
            for scene in voiceover_scenes:
                if reduced >= need_reduce:
                    break
                
                # åªè½¬æ¢ä½é‡è¦æ€§åœºæ™¯
                if scene.importance < 0.5 and scene.dialogue and len(scene.dialogue) > 30:
                    scene.audio_mode = AudioMode.ORIGINAL
                    scene.narration = ""
                    scene.reason = "æ¯”ä¾‹è°ƒæ•´:è§£è¯´â†’åŸå£°"
                    reduced += 1
            
            print(f"   æ¯”ä¾‹è°ƒæ•´: è½¬æ¢{reduced}ä¸ªè§£è¯´åœºæ™¯ä¸ºåŸå£°")
        
        # è§£è¯´è¿‡å°‘æ—¶å¢åŠ 
        elif current_ratio < target_ratio - 0.05:  # ä½äºç›®æ ‡5%ä»¥ä¸Šæ‰è°ƒæ•´
            need_convert = int(total * target_ratio) - voiceover_count
            
            # æŒ‰é‡è¦æ€§æ’åºåŸå£°åœºæ™¯ï¼ˆä½é‡è¦æ€§ä¼˜å…ˆè½¬æ¢ï¼‰
            original_scenes = [s for s in active_scenes if s.audio_mode == AudioMode.ORIGINAL]
            original_scenes.sort(key=lambda x: x.importance)
            
            to_convert = []
            for scene in original_scenes:
                if len(to_convert) >= need_convert:
                    break
                
                # ä¿ç•™æé«˜é‡è¦æ€§åœºæ™¯çš„åŸå£°
                if scene.importance >= 0.85:
                    continue
                
                to_convert.append(scene)
            
            # æ‰¹é‡ç”Ÿæˆè§£è¯´
            if to_convert and self.llm_model:
                narrations = self._batch_generate_narrations(to_convert, self.episode_plot or "", "å¹½é»˜")
                
                converted = 0
                for i, scene in enumerate(to_convert):
                    if i < len(narrations) and narrations[i] and len(narrations[i]) >= 5:
                        scene.audio_mode = AudioMode.VOICEOVER
                        scene.narration = narrations[i]
                        scene.reason = "æ¯”ä¾‹è°ƒæ•´:åŸå£°â†’è§£è¯´"
                        converted += 1
                    else:
                        # å•ç‹¬AIæ€»ç»“
                        fallback = self._ai_summarize_dialogue(scene.dialogue)
                        if fallback and len(fallback) >= 5:
                            scene.audio_mode = AudioMode.VOICEOVER
                            scene.narration = fallback
                            scene.reason = "æ¯”ä¾‹è°ƒæ•´:åŸå£°â†’è§£è¯´"
                            converted += 1
                
                print(f"   æ¯”ä¾‹è°ƒæ•´: è½¬æ¢{converted}ä¸ªåœºæ™¯ä¸ºè§£è¯´")
        else:
            print(f"   æ¯”ä¾‹è°ƒæ•´: æ— éœ€è°ƒæ•´ï¼ˆè¯¯å·®åœ¨Â±5%å†…ï¼‰")
        
        return scenes
    
    def _ai_summarize(self, text: str) -> str:
        """
        ç”¨AIæ€»ç»“æ–‡æœ¬ v5.5
        
        ä¿®å¤ï¼šæ­£ç¡®å¤„ç†Messageå¯¹è±¡çš„å±æ€§è®¿é—®
        """
        if not self.llm_model:
            return ""
        
        try:
            import ollama
            
            prompt = f"""ç”¨100å­—æ€»ç»“ä»¥ä¸‹å¯¹è¯çš„ä¸»è¦å‰§æƒ…ï¼š

{text[:2000]}

å‰§æƒ…æ€»ç»“ï¼š"""
            
            response = ollama.chat(
                model=self.llm_model,
                messages=[{'role': 'user', 'content': prompt}],
                options={'num_predict': 500, 'temperature': 0.3}
            )
            
            # è·å–å†…å®¹ï¼ˆv5.5ä¿®å¤ï¼šæ­£ç¡®è®¿é—®Messageå¯¹è±¡å±æ€§ï¼‰
            # v5.8.0: Structuredæ ¼å¼è§£æï¼Œç»ä¸ä½¿ç”¨thinking
            msg = response.get('message', {})
            result = ""
            
            if hasattr(msg, 'content') and msg.content:
                result = msg.content.strip()
            
            # v5.7.3: contentä¸ºç©ºè¿”å›ç©ºï¼Œä¸ä»thinkingæå–
            return self._filter_sensitive(result)
            
        except Exception as e:
            return ""
    
    def _ai_generate_narration(self, dialogue: str, style: str) -> str:
        """
        ç”¨AIç”Ÿæˆå•æ¡è§£è¯´ v5.5
        
        æ³¨æ„ï¼šv5.5ä¸»è¦ä½¿ç”¨æ‰¹é‡ç”Ÿæˆ(_batch_generate_narrations)
        æ­¤å‡½æ•°ä¿ç•™ä½œä¸ºå¤‡ç”¨æˆ–å•åœºæ™¯å¤„ç†
        
        ä¿®å¤ï¼šnum_predictæå‡åˆ°500ï¼Œæ­£ç¡®è®¿é—®Messageå±æ€§
        """
        if not self.llm_model or not dialogue:
            return ""
        
        try:
            import ollama
            
            # v5.7.2: æç®€promptï¼Œç¦æ­¢æ€è€ƒ
            dialogue_short = dialogue[:80] if dialogue else ""
            prompt = f"/no_think\n{style}è§£è¯´ï¼ˆ15-25å­—ï¼‰ï¼š{dialogue_short}\nç›´æ¥è¾“å‡ºï¼š"
            
            response = ollama.chat(
                model=self.llm_model,
                messages=[{'role': 'user', 'content': prompt}],
                options={
                    'num_predict': 500,  # v5.5: å¢åŠ åˆ°500ç¡®ä¿thinkingå®Œæˆ
                    'temperature': 0.5,
                    'top_p': 0.9,
                }
            )
            
            # v5.8.0: Structuredæ ¼å¼è§£æï¼Œç»ä¸ä½¿ç”¨thinking
            msg = response.get('message', {})
            result = ""
            
            if hasattr(msg, 'content') and msg.content:
                result = msg.content.strip()
            
            # v5.7.3: contentä¸ºç©ºè¿”å›ç©ºï¼Œä¸ä»thinkingæå–
            if not result:
                return ""
            
            # æ¸…ç†æ ¼å¼
            result = result.replace('è§£è¯´ï¼š', '').replace('è§£è¯´:', '')
            result = result.replace('æ—ç™½ï¼š', '').replace('æ—ç™½:', '')
            result = result.strip('"\'""''')
            result = re.sub(r'^[\d]+[\.ã€]\s*', '', result)
            
            # v5.7: æ¸…æ´—åƒåœ¾å†…å®¹å¹¶éªŒè¯
            result = clean_narration_text(result)
            result = self._filter_sensitive(result)
            
            if not validate_narration(result):
                return ""
            
            return result
            
        except Exception as e:
            return ""
    
    def _simple_ai_generate(self, dialogue: str, style: str) -> str:
        """
        v5.7.2ï¼šè¶…ç®€åŒ–AIç”Ÿæˆï¼ˆä½œä¸ºç¬¬äºŒæ¬¡å…œåº•ï¼‰
        ä½¿ç”¨æœ€ç®€å•çš„promptç¡®ä¿ç”ŸæˆæˆåŠŸ
        """
        if not self.llm_model or not dialogue:
            return ""
        
        try:
            import ollama
            
            # v5.7.2: æç®€prompt
            prompt = f"/no_think\næè¿°ï¼ˆ10å­—ï¼‰ï¼š{dialogue[:40]}\nè¾“å‡ºï¼š"
            
            response = ollama.chat(
                model=self.llm_model,
                messages=[{'role': 'user', 'content': prompt}],
                options={
                    'num_predict': 100,
                    'temperature': 0.3,
                }
            )
            
            # v5.8.0: Structuredæ ¼å¼è§£æï¼Œç»ä¸ä½¿ç”¨thinking
            msg = response.get('message', {})
            result = ""
            
            if hasattr(msg, 'content') and msg.content:
                result = msg.content.strip()
            
            # v5.7.3: contentä¸ºç©ºè¿”å›ç©º
            if result:
                result = clean_narration_text(result)
                result = self._filter_sensitive(result)
            
            return result if validate_narration(result) else ""
            
        except Exception:
            return ""
    
    def _keyword_based_generate(self, dialogue: str, style: str) -> str:
        """
        v5.7.2ï¼šåŸºäºå…³é”®è¯ç”Ÿæˆï¼ˆä½œä¸ºæœ€åå…œåº•ï¼‰
        æå–å¯¹è¯ä¸­çš„å…³é”®åŠ¨ä½œ/åè¯ç”Ÿæˆç®€å•è§£è¯´
        """
        if not dialogue:
            return ""
        
        try:
            import ollama
            
            # v5.7.2: æç®€prompt
            prompt = f"/no_think\nåŠ¨ä½œï¼ˆ5å­—ï¼‰ï¼š{dialogue[:25]}\nè¾“å‡ºï¼š"
            
            response = ollama.chat(
                model=self.llm_model,
                messages=[{'role': 'user', 'content': prompt}],
                options={
                    'num_predict': 50,
                    'temperature': 0.2,
                }
            )
            
            # v5.8.0: Structuredæ ¼å¼è§£æï¼Œç»ä¸ä½¿ç”¨thinking
            msg = response.get('message', {})
            result = ""
            
            if hasattr(msg, 'content') and msg.content:
                result = msg.content.strip()
            
            # v5.7.3: contentä¸ºç©ºè¿”å›ç©º
            if result:
                result = clean_narration_text(result)
                result = self._filter_sensitive(result)
            
            return result if len(result) >= 5 else ""
            
        except Exception:
            return ""
    
    def _optimize_continuity(self, scenes: List[SceneSegment]) -> List[SceneSegment]:
        """
        ä¼˜åŒ–å‰§æƒ…è¿è´¯æ€§
        """
        # è§„åˆ™1ï¼šå»é™¤é‡å¤è§£è¯´
        scenes = self._remove_duplicate_narrations(scenes)
        
        # è§„åˆ™2ï¼šä¸èƒ½è¿ç»­è¿‡å¤šè§£è¯´ï¼ˆä½†å…è®¸æ›´å¤šï¼‰
        max_consecutive = 10 if self.media_type == "tv" else 6
        consecutive_voiceover = 0
        
        for scene in scenes:
            if scene.audio_mode == AudioMode.VOICEOVER:
                consecutive_voiceover += 1
                if consecutive_voiceover > max_consecutive and scene.dialogue:
                    scene.audio_mode = AudioMode.ORIGINAL
                    scene.narration = ""
                    scene.reason = "é˜²æ­¢è¿ç»­è§£è¯´"
                    consecutive_voiceover = 0
            else:
                consecutive_voiceover = 0
        
        return scenes
    
    def _remove_duplicate_narrations(self, scenes: List[SceneSegment]) -> List[SceneSegment]:
        """æ£€æµ‹å¹¶å»é™¤é‡å¤è§£è¯´"""
        last_narration = ""
        
        for scene in scenes:
            if scene.audio_mode != AudioMode.VOICEOVER:
                last_narration = ""
                continue
            
            if scene.narration:
                # å®Œå…¨ç›¸åŒ
                if scene.narration == last_narration:
                    scene.audio_mode = AudioMode.ORIGINAL
                    scene.reason = "å»é™¤é‡å¤è§£è¯´"
                    scene.narration = ""
                    continue
                
                # ç›¸ä¼¼åº¦æ£€æŸ¥
                if last_narration and len(scene.narration) > 5:
                    if scene.narration in last_narration or last_narration in scene.narration:
                        scene.audio_mode = AudioMode.ORIGINAL
                        scene.reason = "å»é™¤ç›¸ä¼¼è§£è¯´"
                        scene.narration = ""
                        continue
            
            last_narration = scene.narration
        
        return scenes
    
    def _compile_narration_text(self, scenes: List[SceneSegment]) -> str:
        """ç¼–è¯‘å®Œæ•´è§£è¯´æ–‡æœ¬ï¼ˆv5.6å¢å¼ºï¼šåŒ…å«é’©å­å’Œç»“å°¾ï¼‰"""
        narrations = []
        
        # v5.6ï¼šæ·»åŠ é’©å­å¼€åœº
        if self.hook_opening:
            narrations.append(f"[å¼€åœº] {self.hook_opening}")
            narrations.append("")  # ç©ºè¡Œåˆ†éš”
        
        # ä¸»ä½“è§£è¯´
        for scene in scenes:
            if scene.audio_mode == AudioMode.VOICEOVER and scene.narration:
                narrations.append(scene.narration)
        
        # v5.6ï¼šæ·»åŠ æ‚¬å¿µç»“å°¾
        if self.suspense_ending:
            narrations.append("")  # ç©ºè¡Œåˆ†éš”
            narrations.append(f"[ç»“å°¾] {self.suspense_ending}")
        
        return "\n".join(narrations)
    
    def _is_ad_content(self, text: str) -> bool:
        """
        v5.7.1ï¼šæ£€æµ‹å¹¿å‘Šå†…å®¹
        """
        if not text:
            return False
        
        # å¹¿å‘Šç‰¹å¾æ¨¡å¼
        ad_patterns = [
            r'ç”¨ç—›[ï¹”;]',
            r'ç”¨ç»æ•Œ',
            r'å®¶ä¸­å¸¸å¤‡',
            r'é‚€æ‚¨è§‚çœ‹',
            r'æ•™æ‚¨è§‚çœ‹',
            r'å·¨é¢—è¯è°ˆ',
            r'è‹¦çº¢åˆ©ç„‰',
            r'ç²¾é€šç”µå­æ¡ˆ',
            r'ç©¿è¢«çš®å‘è†',
            r'èµåŠ©æ’­å‡º',
            r'ç‹¬å®¶å† å',
            r'[ï¹”;]{3,}',  # è¿ç»­åˆ†å·ï¼ˆWhisperä¹±ç ç‰¹å¾ï¼‰
        ]
        
        for pattern in ad_patterns:
            if re.search(pattern, text):
                return True
        
        # é«˜å¯†åº¦åˆ†å·æ£€æµ‹ï¼ˆå¹¿å‘Šä¹±ç ç‰¹å¾ï¼‰
        if text.count('ï¹”') > 2 or text.count(';') > 3:
            return True
        
        return False
    
    def _filter_sensitive(self, text: str) -> str:
        """è¿‡æ»¤æ•æ„Ÿè¯"""
        if not text:
            return ""
        result = text
        for word in SENSITIVE_WORDS:
            if word in result:
                result = result.replace(word, "")
        return result.strip()
    
    def _is_low_quality(self, text: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ˜¯ä½è´¨é‡å†…å®¹"""
        if not text or len(text) < 5:
            return True
        for pattern in BAD_PATTERNS:
            if pattern in text:
                return True
        return False


def create_production_timeline(scenes: List[SceneSegment]) -> List[Dict]:
    """åˆ›å»ºæœ€ç»ˆåˆ¶ä½œæ—¶é—´çº¿"""
    timeline = []
    output_time = 0.0
    
    for scene in scenes:
        if scene.audio_mode == AudioMode.SKIP:
            continue
        
        item = {
            'scene_id': scene.scene_id,
            'source_start': scene.start_time,
            'source_end': scene.end_time,
            'output_start': output_time,
            'output_end': output_time + scene.duration,
            'audio_mode': scene.audio_mode.value,
            'narration': scene.narration,
            'dialogue': scene.dialogue,
            'emotion': scene.emotion,
            'reason': scene.reason,
        }
        
        timeline.append(item)
        output_time += scene.duration
    
    return timeline


# æµ‹è¯•
if __name__ == "__main__":
    engine = NarrationEngine(use_ai=True, media_type="tv", episode=1)
    
    test_scenes = [
        {'start_time': 0, 'end_time': 30, 'dialogue': 'ä½ æ˜¯è°ï¼Ÿä¸ºä»€ä¹ˆè¦æ¥è¿™é‡Œï¼Ÿ', 'emotion': 'angry', 'importance': 0.9},
        {'start_time': 30, 'end_time': 60, 'dialogue': 'æˆ‘æœ‰è¯è¦å‘Šè¯‰ä½ ', 'emotion': 'neutral', 'importance': 0.5},
        {'start_time': 60, 'end_time': 90, 'dialogue': '', 'emotion': 'neutral', 'importance': 0.2},
        {'start_time': 90, 'end_time': 120, 'dialogue': 'è¿™ä»¶äº‹æƒ…éå¸¸é‡è¦ï¼Œä½ å¿…é¡»çŸ¥é“çœŸç›¸', 'emotion': 'sad', 'importance': 0.8},
    ]
    
    segments, narration = engine.analyze_and_generate(test_scenes, "æµ‹è¯•å‰§", "å¹½é»˜")
    
    print("\næœ€ç»ˆæ—¶é—´çº¿:")
    for seg in segments:
        mode = "[O]" if seg.audio_mode == AudioMode.ORIGINAL else ("[V]" if seg.audio_mode == AudioMode.VOICEOVER else "[S]")
        print(f"  {seg.start_time:.0f}s-{seg.end_time:.0f}s: {mode} - {seg.reason}")
        if seg.narration:
            print(f"      è§£è¯´: {seg.narration}")
