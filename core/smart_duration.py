# core/smart_duration.py - æ™ºèƒ½æ—¶é•¿è®¡ç®—
"""
SmartVideoClipper - æ™ºèƒ½æ—¶é•¿è®¡ç®—å™¨

æ ¸å¿ƒåŸåˆ™ï¼š
1. ä¸ç¡¬æ€§é™åˆ¶æ—¶é•¿ï¼Œæ ¹æ®å†…å®¹å†³å®š
2. ä¿ç•™æ‰€æœ‰ç²¾å½©åœºæ™¯
3. å‹ç¼©è¿‡æ¸¡/æ— æ„ä¹‰åœºæ™¯

è¾“å‡ºæ—¶é•¿ = ç²¾å½©åœºæ™¯æ€»æ—¶é•¿ + å¿…è¦è¿‡æ¸¡
"""

from typing import List, Dict, Tuple


def calculate_smart_duration(
    scenes: List[Dict],
    min_duration: int = 180,  # æœ€çŸ­3åˆ†é’Ÿ
    max_duration: int = 1200,  # æœ€é•¿20åˆ†é’Ÿ
) -> Tuple[int, List[Dict]]:
    """
    æ™ºèƒ½è®¡ç®—æœ€ä½³è¾“å‡ºæ—¶é•¿
    
    è¿”å›ï¼š(å»ºè®®æ—¶é•¿, ç­›é€‰åçš„åœºæ™¯åˆ—è¡¨)
    """
    print("\n[DURATION] æ™ºèƒ½åˆ†ææœ€ä½³æ—¶é•¿...")
    
    # æŒ‰é‡è¦æ€§åˆ†ç±»åœºæ™¯
    critical_scenes = []  # å¿…é¡»ä¿ç•™ï¼ˆé«˜åˆ†å¯¹è¯ã€æƒ…æ„Ÿçˆ†å‘ï¼‰
    important_scenes = []  # å»ºè®®ä¿ç•™ï¼ˆä¸­ç­‰é‡è¦æ€§ï¼‰
    optional_scenes = []   # å¯é€‰ï¼ˆä½é‡è¦æ€§è¿‡æ¸¡ï¼‰
    
    for scene in scenes:
        importance = scene.get('importance', 0.5)
        dialogue = scene.get('dialogue', '')
        emotion = scene.get('emotion', 'neutral')
        
        # åˆ†ç±»é€»è¾‘
        if importance >= 0.8 or emotion in ['angry', 'sad', 'excited']:
            # é«˜é‡è¦æ€§æˆ–å¼ºæƒ…æ„Ÿ â†’ å¿…é¡»ä¿ç•™
            critical_scenes.append(scene)
        elif importance >= 0.5 or len(dialogue) > 30:
            # ä¸­ç­‰é‡è¦æ€§æˆ–æœ‰å¯¹è¯ â†’ å»ºè®®ä¿ç•™
            important_scenes.append(scene)
        else:
            # ä½é‡è¦æ€§ â†’ å¯é€‰
            optional_scenes.append(scene)
    
    # è®¡ç®—å„ç±»åœºæ™¯æ—¶é•¿
    critical_duration = sum(s['end_time'] - s['start_time'] for s in critical_scenes)
    important_duration = sum(s['end_time'] - s['start_time'] for s in important_scenes)
    optional_duration = sum(s['end_time'] - s['start_time'] for s in optional_scenes)
    
    print(f"   å¿…é¡»ä¿ç•™: {len(critical_scenes)}ä¸ªåœºæ™¯, {critical_duration:.0f}ç§’")
    print(f"   å»ºè®®ä¿ç•™: {len(important_scenes)}ä¸ªåœºæ™¯, {important_duration:.0f}ç§’")
    print(f"   å¯é€‰åœºæ™¯: {len(optional_scenes)}ä¸ªåœºæ™¯, {optional_duration:.0f}ç§’")
    
    # å†³å®šæœ€ç»ˆæ—¶é•¿
    # ç­–ç•¥ï¼šå¿…é¡» + å»ºè®® + éƒ¨åˆ†å¯é€‰ï¼ˆå¦‚æœè¿˜æœ‰ç©ºé—´ï¼‰
    
    selected_scenes = critical_scenes.copy()
    current_duration = critical_duration
    
    # æ·»åŠ å»ºè®®åœºæ™¯
    for scene in important_scenes:
        scene_duration = scene['end_time'] - scene['start_time']
        if current_duration + scene_duration <= max_duration:
            selected_scenes.append(scene)
            current_duration += scene_duration
    
    # å¦‚æœè¿˜ä¸å¤Ÿæœ€çŸ­æ—¶é•¿ï¼Œæ·»åŠ å¯é€‰åœºæ™¯
    if current_duration < min_duration:
        for scene in optional_scenes:
            scene_duration = scene['end_time'] - scene['start_time']
            if current_duration + scene_duration <= max_duration:
                selected_scenes.append(scene)
                current_duration += scene_duration
            if current_duration >= min_duration:
                break
    
    # æŒ‰æ—¶é—´æ’åº
    selected_scenes.sort(key=lambda x: x['start_time'])
    
    # ç¡®ä¿åœ¨åˆç†èŒƒå›´å†…
    final_duration = max(min_duration, min(current_duration, max_duration))
    
    print(f"\n   ğŸ“Š æ™ºèƒ½å»ºè®®æ—¶é•¿: {final_duration:.0f}ç§’ ({final_duration/60:.1f}åˆ†é’Ÿ)")
    print(f"   é€‰æ‹©åœºæ™¯: {len(selected_scenes)}ä¸ª")
    
    return int(final_duration), selected_scenes


def decide_audio_mode(scene: Dict) -> str:
    """
    å†³å®šåœºæ™¯ä½¿ç”¨åŸå£°è¿˜æ˜¯è§£è¯´
    
    è¿”å›: 'original' æˆ– 'voiceover'
    
    åŸå£°åœºæ™¯ï¼š
    - ç²¾å½©å¯¹è¯ï¼ˆæœ‰æƒ…æ„Ÿï¼‰
    - åŠ¨ä½œåœºé¢
    - éŸ³ä¹/æ­Œæ›²
    - é‡è¦å°è¯
    
    è§£è¯´åœºæ™¯ï¼š
    - è¿‡æ¸¡ç”»é¢
    - éœ€è¦èƒŒæ™¯è§£é‡Š
    - å¯¹è¯ä¸é‡è¦
    """
    dialogue = scene.get('dialogue', '')
    emotion = scene.get('emotion', 'neutral')
    scene_type = scene.get('scene_type', 'unknown')
    importance = scene.get('importance', 0.5)
    
    # å¼ºæƒ…æ„Ÿ â†’ åŸå£°
    if emotion in ['angry', 'sad', 'excited', 'happy']:
        return 'original'
    
    # åŠ¨ä½œåœºé¢ â†’ åŸå£°
    if scene_type == 'action':
        return 'original'
    
    # æœ‰é‡è¦å¯¹è¯ï¼ˆé•¿åº¦>20å­—ï¼‰â†’ åŸå£°
    if len(dialogue) > 20 and importance >= 0.6:
        return 'original'
    
    # é«˜é‡è¦æ€§ â†’ åŸå£°
    if importance >= 0.75:
        return 'original'
    
    # å…¶ä»– â†’ è§£è¯´
    return 'voiceover'


def create_mixed_timeline(
    scenes: List[Dict],
    target_duration: int = None
) -> List[Dict]:
    """
    åˆ›å»ºåŸå£°/è§£è¯´æ··åˆæ—¶é—´çº¿
    
    ç¡®ä¿ï¼š
    1. åŸå£°å’Œè§£è¯´äº¤æ›¿å‡ºç°
    2. ä¸ä¼šè¿ç»­å¤ªé•¿è§£è¯´
    3. ç²¾å½©åœºæ™¯ä¿ç•™åŸå£°
    """
    if not scenes:
        return []
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šæ—¶é•¿ï¼Œä½¿ç”¨æ™ºèƒ½è®¡ç®—
    if target_duration is None:
        target_duration, scenes = calculate_smart_duration(scenes)
    
    timeline = []
    output_time = 0
    
    voiceover_count = 0
    original_count = 0
    
    for scene in scenes:
        # å†³å®šéŸ³é¢‘æ¨¡å¼
        audio_mode = decide_audio_mode(scene)
        
        # é˜²æ­¢è¿ç»­å¤ªå¤šè§£è¯´ï¼ˆæœ€å¤š3ä¸ªè¿ç»­è§£è¯´åå¼ºåˆ¶åŸå£°ï¼‰
        consecutive_voiceover = sum(1 for t in timeline[-3:] if t.get('audio_mode') == 'voiceover')
        if consecutive_voiceover >= 3 and audio_mode == 'voiceover':
            # å¦‚æœåœºæ™¯æœ‰å¯¹è¯ï¼Œå¼ºåˆ¶ä½¿ç”¨åŸå£°
            if scene.get('dialogue'):
                audio_mode = 'original'
        
        scene_duration = scene['end_time'] - scene['start_time']
        
        # æ·»åŠ åˆ°æ—¶é—´çº¿
        item = {
            'scene_id': scene.get('scene_id', len(timeline) + 1),
            'source_start': scene['start_time'],
            'source_end': scene['end_time'],
            'output_start': output_time,
            'output_end': output_time + scene_duration,
            'audio_mode': audio_mode,
            'dialogue': scene.get('dialogue', '')[:50],
            'narration': scene.get('narration', ''),
            'emotion': scene.get('emotion', 'neutral'),
        }
        
        timeline.append(item)
        output_time += scene_duration
        
        if audio_mode == 'original':
            original_count += 1
        else:
            voiceover_count += 1
    
    print(f"\n   ğŸ“‹ æ—¶é—´çº¿ç”Ÿæˆå®Œæˆ:")
    print(f"      åŸå£°åœºæ™¯: {original_count} ({original_count*100//(original_count+voiceover_count) if (original_count+voiceover_count) > 0 else 0}%)")
    print(f"      è§£è¯´åœºæ™¯: {voiceover_count} ({voiceover_count*100//(original_count+voiceover_count) if (original_count+voiceover_count) > 0 else 0}%)")
    print(f"      æ€»æ—¶é•¿: {output_time:.0f}ç§’")
    
    return timeline


# æµ‹è¯•
if __name__ == "__main__":
    # æ¨¡æ‹Ÿåœºæ™¯æ•°æ®
    test_scenes = [
        {'start_time': 0, 'end_time': 30, 'importance': 0.9, 'dialogue': 'ä½ æ˜¯è°ï¼Ÿä½ æ¥è¿™é‡Œå¹²ä»€ä¹ˆï¼Ÿ', 'emotion': 'angry'},
        {'start_time': 30, 'end_time': 45, 'importance': 0.3, 'dialogue': '', 'emotion': 'neutral'},
        {'start_time': 45, 'end_time': 90, 'importance': 0.8, 'dialogue': 'æˆ‘è¦å‘Šè¯‰ä½ ä¸€ä¸ªç§˜å¯†', 'emotion': 'sad'},
        {'start_time': 90, 'end_time': 120, 'importance': 0.5, 'dialogue': 'å¥½çš„', 'emotion': 'neutral'},
    ]
    
    duration, selected = calculate_smart_duration(test_scenes)
    timeline = create_mixed_timeline(selected)
    
    for item in timeline:
        mode = "ğŸ”ŠåŸå£°" if item['audio_mode'] == 'original' else "ğŸ™ï¸è§£è¯´"
        print(f"  {item['source_start']:.0f}s-{item['source_end']:.0f}s: {mode}")

