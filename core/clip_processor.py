# core/clip_processor.py - ç‰‡æ®µå¤„ç†å™¨ v5.0 (GPUåŠ é€Ÿç‰ˆ)
"""
SmartVideoClipper - ç‰‡æ®µçº§éŸ³é¢‘å¤„ç†

æ ¸å¿ƒåŸåˆ™ï¼š
æ¯ä¸ªç‰‡æ®µç‹¬ç«‹å¤„ç†éŸ³é¢‘ï¼Œä¸æ˜¯å…¨ç¨‹æ··éŸ³ï¼

åŸå£°ç‰‡æ®µï¼šä¿ç•™åŸå§‹éŸ³é¢‘
è§£è¯´ç‰‡æ®µï¼šæ›¿æ¢ä¸ºå¯¹åº”çš„TTSéŸ³é¢‘

GPUåŠ é€Ÿæ”¯æŒï¼š
- NVIDIA NVENC (10å€é€Ÿåº¦æå‡)
- Intel QSV
- AMD AMF
- è‡ªåŠ¨fallbackåˆ°CPU
"""

import os
import subprocess
import shutil
from pathlib import Path
from typing import List, Dict, Optional, Tuple

# å¯¼å…¥GPUç¼–ç å™¨
try:
    from gpu_encoder import get_video_codec_args, is_hardware_available, get_encoder
    GPU_AVAILABLE = True
except ImportError:
    GPU_AVAILABLE = False
    def get_video_codec_args(quality='fast'):
        return ['-c:v', 'libx264', '-preset', 'fast']
    def is_hardware_available():
        return False


def extract_clip_with_audio_mode(
    source_video: str,
    start_time: float,
    end_time: float,
    output_path: str,
    audio_mode: str,
    narration_audio: str = None,
    narration_start: float = 0,
    narration_duration: float = None
) -> bool:
    """
    æå–å•ä¸ªç‰‡æ®µï¼Œæ ¹æ®audio_modeå¤„ç†éŸ³é¢‘
    
    å‚æ•°ï¼š
        source_video: æºè§†é¢‘
        start_time: å¼€å§‹æ—¶é—´
        end_time: ç»“æŸæ—¶é—´
        output_path: è¾“å‡ºè·¯å¾„
        audio_mode: 'original' æˆ– 'voiceover'
        narration_audio: è§£è¯´éŸ³é¢‘æ–‡ä»¶ï¼ˆä»…voiceoveræ¨¡å¼éœ€è¦ï¼‰
        narration_start: è§£è¯´éŸ³é¢‘çš„èµ·å§‹ä½ç½®
        narration_duration: è§£è¯´éŸ³é¢‘çš„æŒç»­æ—¶é—´
    
    è¿”å›ï¼š
        æ˜¯å¦æˆåŠŸ
    """
    duration = end_time - start_time
    
    # è·å–GPUåŠ é€Ÿç¼–ç å‚æ•°
    video_codec_args = get_video_codec_args('fast')
    
    if audio_mode == 'original':
        # åŸå£°æ¨¡å¼ï¼šç›´æ¥æå–ï¼Œä¿ç•™åŸå§‹éŸ³é¢‘
        # æ³¨æ„ï¼šç»Ÿä¸€ç¼–ç å‚æ•°ï¼Œç¡®ä¿æ‹¼æ¥æ—¶å…¼å®¹
        cmd = [
            'ffmpeg', '-y',
            '-ss', str(start_time),
            '-i', source_video,
            '-t', str(duration),
        ] + video_codec_args + [  # GPUåŠ é€Ÿç¼–ç 
            '-c:a', 'aac',
            '-ar', '44100',      # ç»Ÿä¸€éŸ³é¢‘é‡‡æ ·ç‡
            '-ac', '2',          # ç»Ÿä¸€åŒå£°é“
            '-loglevel', 'error',
            output_path
        ]
        result = subprocess.run(cmd, capture_output=True, encoding='utf-8', errors='ignore')
        
    elif audio_mode == 'voiceover' and narration_audio and os.path.exists(narration_audio):
        # è§£è¯´æ¨¡å¼ï¼šæå–è§†é¢‘ï¼Œæ›¿æ¢éŸ³é¢‘
        
        # è®¡ç®—è§£è¯´éŸ³é¢‘çš„ä½¿ç”¨èŒƒå›´
        if narration_duration is None:
            narration_duration = duration
        
        # å…ˆæå–è§†é¢‘ï¼ˆæ— éŸ³é¢‘ï¼‰
        temp_video = output_path + '.temp.mp4'
        cmd = [
            'ffmpeg', '-y',
            '-ss', str(start_time),
            '-i', source_video,
            '-t', str(duration),
        ] + video_codec_args + [  # GPUåŠ é€Ÿç¼–ç 
            '-an',  # æ— éŸ³é¢‘
            '-loglevel', 'error',
            temp_video
        ]
        subprocess.run(cmd, capture_output=True, encoding='utf-8', errors='ignore')
        
        if not os.path.exists(temp_video):
            return False
        
        # æå–å¯¹åº”æ—¶æ®µçš„è§£è¯´éŸ³é¢‘
        temp_audio = output_path + '.temp.wav'
        cmd = [
            'ffmpeg', '-y',
            '-ss', str(narration_start),
            '-i', narration_audio,
            '-t', str(min(duration, narration_duration)),
            '-acodec', 'pcm_s16le',
            '-ar', '44100',
            '-ac', '2',
            '-loglevel', 'error',
            temp_audio
        ]
        subprocess.run(cmd, capture_output=True, encoding='utf-8', errors='ignore')
        
        # åˆå¹¶è§†é¢‘å’Œè§£è¯´éŸ³é¢‘
        if os.path.exists(temp_audio) and os.path.getsize(temp_audio) > 1000:
            cmd = [
                'ffmpeg', '-y',
                '-i', temp_video,
                '-i', temp_audio,
                '-c:v', 'copy',
                '-c:a', 'aac',
                '-shortest',
                '-loglevel', 'error',
                output_path
            ]
            subprocess.run(cmd, capture_output=True, encoding='utf-8', errors='ignore')
        else:
            # è§£è¯´éŸ³é¢‘ä¸å¯ç”¨ï¼Œé™éŸ³å¤„ç†
            cmd = [
                'ffmpeg', '-y',
                '-i', temp_video,
                '-f', 'lavfi', '-i', 'anullsrc=r=44100:cl=stereo',
                '-c:v', 'copy',
                '-c:a', 'aac',
                '-shortest',
                '-loglevel', 'error',
                output_path
            ]
            subprocess.run(cmd, capture_output=True, encoding='utf-8', errors='ignore')
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        try:
            os.remove(temp_video)
            if os.path.exists(temp_audio):
                os.remove(temp_audio)
        except:
            pass
    
    else:
        # é»˜è®¤ï¼šä¿ç•™åŸå£°
        cmd = [
            'ffmpeg', '-y',
            '-ss', str(start_time),
            '-i', source_video,
            '-t', str(duration),
        ] + video_codec_args + [  # GPUåŠ é€Ÿç¼–ç 
            '-c:a', 'aac',
            '-ar', '44100',
            '-ac', '2',
            '-loglevel', 'error',
            output_path
        ]
        subprocess.run(cmd, capture_output=True, encoding='utf-8', errors='ignore')
    
    return os.path.exists(output_path) and os.path.getsize(output_path) > 1000


def process_timeline_clips(
    source_video: str,
    timeline: List[Dict],
    narration_segments: List[Dict],
    output_dir: str
) -> Tuple[List[str], float]:
    """
    å¤„ç†æ—¶é—´çº¿ä¸Šçš„æ‰€æœ‰ç‰‡æ®µ
    
    å‚æ•°ï¼š
        source_video: æºè§†é¢‘
        timeline: æ—¶é—´çº¿åˆ—è¡¨ï¼Œæ¯é¡¹åŒ…å« source_start, source_end, audio_mode, scene_id
        narration_segments: è§£è¯´éŸ³é¢‘ç‰‡æ®µåˆ—è¡¨ï¼Œæ¯é¡¹åŒ…å« audio_path, duration, scene_id
        output_dir: è¾“å‡ºç›®å½•
    
    è¿”å›ï¼š
        (ç‰‡æ®µæ–‡ä»¶åˆ—è¡¨, æ€»æ—¶é•¿)
    """
    print("\n[CLIP] åˆ†æ®µå¤„ç†ç‰‡æ®µ...")
    
    os.makedirs(output_dir, exist_ok=True)
    
    clip_files = []
    total_duration = 0
    
    original_count = 0
    voiceover_count = 0
    
    # æ„å»º scene_id -> éŸ³é¢‘ çš„æ˜ å°„è¡¨ï¼ˆå…³é”®ä¿®å¤ï¼ï¼‰
    narration_map = {}
    for seg in narration_segments:
        scene_id = seg.get('scene_id')
        if scene_id is not None:
            narration_map[scene_id] = seg
    
    print(f"   TTSéŸ³é¢‘æ˜ å°„: {len(narration_map)}ä¸ª")
    
    for i, item in enumerate(timeline):
        clip_path = os.path.join(output_dir, f"clip_{i:04d}.mp4")
        
        source_start = item['source_start']
        source_end = item['source_end']
        audio_mode = item.get('audio_mode', 'original')
        scene_id = item.get('scene_id')
        duration = source_end - source_start
        
        # è·å–å¯¹åº”çš„è§£è¯´éŸ³é¢‘ï¼ˆé€šè¿‡scene_idç²¾ç¡®åŒ¹é…ï¼ï¼‰
        narration_audio = None
        narration_start = 0
        narration_duration = None
        
        if audio_mode == 'voiceover':
            if scene_id in narration_map:
                seg = narration_map[scene_id]
                narration_audio = seg.get('audio_path')
                narration_start = seg.get('start', 0)
                narration_duration = seg.get('duration', duration)
            else:
                # æ²¡æœ‰å¯¹åº”çš„TTSéŸ³é¢‘ï¼Œæ”¹ä¸ºä½¿ç”¨åŸå£°
                print(f"   [WARN] åœºæ™¯{scene_id}æ²¡æœ‰TTSéŸ³é¢‘ï¼Œä½¿ç”¨åŸå£°")
                audio_mode = 'original'
        
        # æå–ç‰‡æ®µ
        success = extract_clip_with_audio_mode(
            source_video=source_video,
            start_time=source_start,
            end_time=source_end,
            output_path=clip_path,
            audio_mode=audio_mode,
            narration_audio=narration_audio,
            narration_start=narration_start,
            narration_duration=narration_duration
        )
        
        if success:
            clip_files.append(clip_path)
            total_duration += duration
            
            if audio_mode == 'original':
                original_count += 1
            else:
                voiceover_count += 1
        
        # è¿›åº¦æ˜¾ç¤º
        if (i + 1) % 10 == 0 or i == len(timeline) - 1:
            print(f"   è¿›åº¦: {i+1}/{len(timeline)} (ğŸ”Š{original_count} ğŸ™ï¸{voiceover_count})")
    
    print(f"[OK] ç‰‡æ®µå¤„ç†å®Œæˆ: {len(clip_files)}ä¸ª, æ€»æ—¶é•¿{total_duration:.0f}ç§’")
    print(f"     åŸå£°: {original_count}, è§£è¯´: {voiceover_count}")
    
    return clip_files, total_duration


def concat_processed_clips(
    clip_files: List[str],
    output_path: str
) -> bool:
    """
    æ‹¼æ¥å¤„ç†åçš„ç‰‡æ®µ
    
    æ‰€æœ‰ç‰‡æ®µå·²ç»å„è‡ªå¤„ç†å¥½éŸ³é¢‘ï¼Œç›´æ¥æ‹¼æ¥å³å¯
    """
    if not clip_files:
        return False
    
    print(f"\n[CONCAT] æ‹¼æ¥ {len(clip_files)} ä¸ªç‰‡æ®µ...")
    
    # å†™å…¥æ–‡ä»¶åˆ—è¡¨
    list_file = output_path + '.list.txt'
    with open(list_file, 'w', encoding='utf-8') as f:
        for clip in clip_files:
            abs_path = os.path.abspath(clip).replace('\\', '/')
            f.write(f"file '{abs_path}'\n")
    
    # æ‹¼æ¥
    cmd = [
        'ffmpeg', '-y',
        '-f', 'concat',
        '-safe', '0',
        '-i', list_file,
        '-c', 'copy',
        '-loglevel', 'error',
        output_path
    ]
    
    result = subprocess.run(cmd, capture_output=True, encoding='utf-8', errors='ignore')
    
    # æ¸…ç†
    try:
        os.remove(list_file)
    except:
        pass
    
    success = os.path.exists(output_path) and os.path.getsize(output_path) > 1000
    
    if success:
        size_mb = os.path.getsize(output_path) / (1024*1024)
        print(f"[OK] æ‹¼æ¥å®Œæˆ: {output_path} ({size_mb:.1f}MB)")
    else:
        print(f"[ERROR] æ‹¼æ¥å¤±è´¥")
    
    return success


# æµ‹è¯•
if __name__ == "__main__":
    print("ç‰‡æ®µå¤„ç†å™¨æµ‹è¯•")
    
    # æµ‹è¯•extract_clip_with_audio_mode
    test_timeline = [
        {'source_start': 0, 'source_end': 10, 'audio_mode': 'original'},
        {'source_start': 10, 'source_end': 20, 'audio_mode': 'voiceover'},
        {'source_start': 20, 'source_end': 30, 'audio_mode': 'original'},
    ]
    print(f"æµ‹è¯•æ—¶é—´çº¿: {test_timeline}")

